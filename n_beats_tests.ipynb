{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNWQPgypv7Tr4LrFqNxozSx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "36JZI-VE8C1e",
        "outputId": "b18cd180-4e49-486f-b505-671c5d91d25c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EasyTSF'...\n",
            "remote: Enumerating objects: 708, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 708 (delta 86), reused 96 (delta 49), pack-reused 560 (from 2)\u001b[K\n",
            "Receiving objects: 100% (708/708), 1.88 MiB | 18.67 MiB/s, done.\n",
            "Resolving deltas: 100% (388/388), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Olyco/EasyTSF.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G6JkPFRy8LVA",
        "outputId": "afd28a94-4bf9-4395-f26b-bed9f7c8f3a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"EasyTSF/requirements.txt\""
      ],
      "metadata": {
        "id": "xuxMN9fT8L1h",
        "outputId": "218db6a0-0380-45e7-880e-968be18b89d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Brotli==1.0.9 (from -r EasyTSF/requirements.txt (line 1))\n",
            "  Downloading Brotli-1.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting certifi==2024.7.4 (from -r EasyTSF/requirements.txt (line 2))\n",
            "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting charset-normalizer==3.3.2 (from -r EasyTSF/requirements.txt (line 3))\n",
            "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting colorama==0.4.6 (from -r EasyTSF/requirements.txt (line 4))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting filelock==3.13.1 (from -r EasyTSF/requirements.txt (line 5))\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting fsspec==2024.6.1 (from -r EasyTSF/requirements.txt (line 6))\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting idna==3.7 (from -r EasyTSF/requirements.txt (line 7))\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting Jinja2==3.1.4 (from -r EasyTSF/requirements.txt (line 8))\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting lightning==2.4.0 (from -r EasyTSF/requirements.txt (line 9))\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting lightning-utilities==0.11.6 (from -r EasyTSF/requirements.txt (line 10))\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting MarkupSafe==2.1.3 (from -r EasyTSF/requirements.txt (line 11))\n",
            "  Downloading MarkupSafe-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mkl-fft==1.3.8 (from -r EasyTSF/requirements.txt (line 12))\n",
            "  Downloading mkl_fft-1.3.8-72-cp311-cp311-manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting mkl-random==1.2.4 (from -r EasyTSF/requirements.txt (line 13))\n",
            "  Downloading mkl_random-1.2.4-92-cp311-cp311-manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting mkl-service==2.4.1 (from -r EasyTSF/requirements.txt (line 14))\n",
            "  Downloading mkl_service-2.4.1-0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 15)) (1.3.0)\n",
            "Collecting networkx==3.3 (from -r EasyTSF/requirements.txt (line 16))\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting numpy==1.26.4 (from -r EasyTSF/requirements.txt (line 17))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==24.1 (from -r EasyTSF/requirements.txt (line 18))\n",
            "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pillow==10.4.0 (from -r EasyTSF/requirements.txt (line 19))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pip==24.2 (from -r EasyTSF/requirements.txt (line 20))\n",
            "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 21)) (1.7.1)\n",
            "Collecting pytorch-lightning==2.4.0 (from -r EasyTSF/requirements.txt (line 22))\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting PyYAML==6.0.1 (from -r EasyTSF/requirements.txt (line 23))\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 24)) (2.32.3)\n",
            "Collecting setuptools==72.1.0 (from -r EasyTSF/requirements.txt (line 25))\n",
            "  Downloading setuptools-72.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy==1.12 (from -r EasyTSF/requirements.txt (line 26))\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting torch==2.4.0 (from -r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchaudio==2.4.0 (from -r EasyTSF/requirements.txt (line 28))\n",
            "  Downloading torchaudio-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchmetrics==1.4.0.post0 (from -r EasyTSF/requirements.txt (line 29))\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting torchvision==0.19.0 (from -r EasyTSF/requirements.txt (line 30))\n",
            "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting tqdm==4.66.5 (from -r EasyTSF/requirements.txt (line 31))\n",
            "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from -r EasyTSF/requirements.txt (line 32))\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting typing_extensions==4.11.0 (from -r EasyTSF/requirements.txt (line 33))\n",
            "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting urllib3==2.2.2 (from -r EasyTSF/requirements.txt (line 34))\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting wheel==0.43.0 (from -r EasyTSF/requirements.txt (line 35))\n",
            "  Downloading wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting torcheval (from -r EasyTSF/requirements.txt (line 36))\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting ray (from -r EasyTSF/requirements.txt (line 37))\n",
            "  Downloading ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting pykan (from -r EasyTSF/requirements.txt (line 38))\n",
            "  Downloading pykan-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pytorch_forecasting (from -r EasyTSF/requirements.txt (line 39))\n",
            "  Downloading pytorch_forecasting-1.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (2025.0.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (12.5.82)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray->-r EasyTSF/requirements.txt (line 37)) (8.2.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray->-r EasyTSF/requirements.txt (line 37)) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray->-r EasyTSF/requirements.txt (line 37)) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray->-r EasyTSF/requirements.txt (line 37)) (5.29.4)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (1.15.3)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (1.6.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (3.11.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (3.6.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->-r EasyTSF/requirements.txt (line 37)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->-r EasyTSF/requirements.txt (line 37)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->-r EasyTSF/requirements.txt (line 37)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->-r EasyTSF/requirements.txt (line 37)) (0.24.0)\n",
            "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (2025.1.1)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (2022.1.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (1.20.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2025.1.1 in /usr/local/lib/python3.11/dist-packages (from intel-openmp>=2024->mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (2025.1.1)\n",
            "Requirement already satisfied: umf==0.10.* in /usr/local/lib/python3.11/dist-packages (from intel-cmplr-lib-ur==2025.1.1->intel-openmp>=2024->mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (1.17.0)\n",
            "Downloading Brotli-1.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Downloading MarkupSafe-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading mkl_fft-1.3.8-72-cp311-cp311-manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mkl_random-1.2.4-92-cp311-cp311-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mkl_service-2.4.1-0-cp311-cp311-manylinux2014_x86_64.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-72.1.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.4.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
            "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl (68.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pykan-0.2.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.1/78.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_forecasting-1.3.0-py3-none-any.whl (197 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.7/197.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Brotli, wheel, urllib3, typing_extensions, tqdm, sympy, setuptools, PyYAML, pykan, pip, pillow, packaging, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, fsspec, filelock, colorama, charset-normalizer, certifi, triton, torcheval, nvidia-cusolver-cu12, nvidia-cudnn-cu12, lightning-utilities, Jinja2, torch, torchvision, torchmetrics, torchaudio, ray, pytorch-lightning, mkl-service, mkl-random, mkl-fft, lightning, pytorch_forecasting\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.4.26\n",
            "    Uninstalling certifi-2025.4.26:\n",
            "      Successfully uninstalled certifi-2025.4.26\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "typing-inspection 0.4.0 requires typing-extensions>=4.12.0, but you have typing-extensions 4.11.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.6.1 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\n",
            "google-cloud-bigquery 3.32.0 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\n",
            "pydantic 2.11.4 requires typing-extensions>=4.12.2, but you have typing-extensions 4.11.0 which is incompatible.\n",
            "pytensor 2.30.3 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\n",
            "dataproc-spark-connect 0.7.3 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Brotli-1.0.9 Jinja2-3.1.4 MarkupSafe-2.1.3 PyYAML-6.0.1 certifi-2024.7.4 charset-normalizer-3.3.2 colorama-0.4.6 filelock-3.13.1 fsspec-2024.6.1 idna-3.7 lightning-2.4.0 lightning-utilities-0.11.6 mkl-fft-1.3.8 mkl-random-1.2.4 mkl-service-2.4.1 networkx-3.3 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 packaging-24.1 pillow-10.4.0 pip-24.2 pykan-0.2.8 pytorch-lightning-2.4.0 pytorch_forecasting-1.3.0 ray-2.46.0 setuptools-72.1.0 sympy-1.12 torch-2.4.0 torchaudio-2.4.0 torcheval-0.0.7 torchmetrics-1.4.0.post0 torchvision-0.19.0 tqdm-4.66.5 triton-3.0.0 typing_extensions-4.11.0 urllib3-2.2.2 wheel-0.43.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "pkg_resources"
                ]
              },
              "id": "90de02eb571646c1b1a4d5c7b100d169"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KAN-BEATS"
      ],
      "metadata": {
        "id": "FWqAKSkS9dsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Интерпретируемый"
      ],
      "metadata": {
        "id": "9FE4BLNx9wRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По 48 часам прогноз на 12 часов, 10 переменных,\n",
        "num_blocks=[2, 2],\n",
        "num_block_layers=[4, 4],\n",
        "widths=[64, 64],\n",
        "sharing=False,\n",
        "expansion_coefficient_lengths=[3, 12]"
      ],
      "metadata": {
        "id": "4jTdXBxTdK7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/KAN_BEATS/ECL_interp.py"
      ],
      "metadata": {
        "id": "e7hKIGSI9gqT",
        "outputId": "aeab8250-9488-49d1-8348-4e6cdad02648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "257774  21038  0.377660   9\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "\n",
            "[210430 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21043   21043  0.051095   0\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "...       ...       ...  ..\n",
            "260404  23668  0.196809   9\n",
            "260405  23669  0.199468   9\n",
            "260406  23670  0.199468   9\n",
            "260407  23671  0.091755   9\n",
            "260408  23672  0.117021   9\n",
            "\n",
            "[26300 rows x 3 columns]\n",
            "        index  variable  id\n",
            "23673   23673  0.467153   0\n",
            "23674   23674  0.452555   0\n",
            "23675   23675  0.437956   0\n",
            "23676   23676  0.664234   0\n",
            "23677   23677  0.452555   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[26310 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 20984 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "   | Name                                      | Type                  | Params | Mode \n",
            "---------------------------------------------------------------------------------------------\n",
            "0  | loss                                      | MAE                   | 0      | train\n",
            "1  | logging_metrics                           | ModuleList            | 0      | train\n",
            "2  | logging_metrics.0                         | SMAPE                 | 0      | train\n",
            "3  | logging_metrics.1                         | MAE                   | 0      | train\n",
            "4  | logging_metrics.2                         | RMSE                  | 0      | train\n",
            "5  | logging_metrics.3                         | MAPE                  | 0      | train\n",
            "6  | logging_metrics.4                         | MASE                  | 0      | train\n",
            "7  | logging_metrics.5                         | customR2Score         | 0      | train\n",
            "8  | net_blocks                                | ModuleList            | 362 K  | train\n",
            "9  | net_blocks.0                              | KANBEATSTrendBlock    | 90.3 K | train\n",
            "10 | net_blocks.0.kan                          | eff_KAN               | 90.1 K | train\n",
            "11 | net_blocks.0.kan.layers                   | ModuleList            | 90.1 K | train\n",
            "12 | net_blocks.0.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "13 | net_blocks.0.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "14 | net_blocks.0.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "15 | net_blocks.0.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "16 | net_blocks.0.kan.layers.2                 | KANLinear             | 32.8 K | train\n",
            "17 | net_blocks.0.kan.layers.2.base_activation | SiLU                  | 0      | train\n",
            "18 | net_blocks.0.theta_f_fc                   | Linear                | 192    | train\n",
            "19 | net_blocks.1                              | KANBEATSTrendBlock    | 90.3 K | train\n",
            "20 | net_blocks.1.kan                          | eff_KAN               | 90.1 K | train\n",
            "21 | net_blocks.1.kan.layers                   | ModuleList            | 90.1 K | train\n",
            "22 | net_blocks.1.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "23 | net_blocks.1.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "24 | net_blocks.1.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "25 | net_blocks.1.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "26 | net_blocks.1.kan.layers.2                 | KANLinear             | 32.8 K | train\n",
            "27 | net_blocks.1.kan.layers.2.base_activation | SiLU                  | 0      | train\n",
            "28 | net_blocks.1.theta_f_fc                   | Linear                | 192    | train\n",
            "29 | net_blocks.2                              | KANBEATSSeasonalBlock | 90.9 K | train\n",
            "30 | net_blocks.2.kan                          | eff_KAN               | 90.1 K | train\n",
            "31 | net_blocks.2.kan.layers                   | ModuleList            | 90.1 K | train\n",
            "32 | net_blocks.2.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "33 | net_blocks.2.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "34 | net_blocks.2.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "35 | net_blocks.2.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "36 | net_blocks.2.kan.layers.2                 | KANLinear             | 32.8 K | train\n",
            "37 | net_blocks.2.kan.layers.2.base_activation | SiLU                  | 0      | train\n",
            "38 | net_blocks.2.theta_f_fc                   | Linear                | 768    | train\n",
            "39 | net_blocks.3                              | KANBEATSSeasonalBlock | 90.9 K | train\n",
            "40 | net_blocks.3.kan                          | eff_KAN               | 90.1 K | train\n",
            "41 | net_blocks.3.kan.layers                   | ModuleList            | 90.1 K | train\n",
            "42 | net_blocks.3.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "43 | net_blocks.3.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "44 | net_blocks.3.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "45 | net_blocks.3.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "46 | net_blocks.3.kan.layers.2                 | KANLinear             | 32.8 K | train\n",
            "47 | net_blocks.3.kan.layers.2.base_activation | SiLU                  | 0      | train\n",
            "48 | net_blocks.3.theta_f_fc                   | Linear                | 768    | train\n",
            "---------------------------------------------------------------------------------------------\n",
            "362 K     Trainable params\n",
            "0         Non-trainable params\n",
            "362 K     Total params\n",
            "1.449     Total estimated model params size (MB)\n",
            "49        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/content/EasyTSF/easytsf/model/KAN_BEATS.py:1228: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  98% 98/100 [00:05<00:00, 17.74it/s]\n",
            "LR finder stopped early after 98 steps due to diverging loss.\n",
            "Learning rate set to 0.0007079457843841378\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_fde12c81-6b15-4746-83f2-bb4dd2638f19.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_fde12c81-6b15-4746-83f2-bb4dd2638f19.ckpt\n",
            "suggested learning rate: 0.0007079457843841378\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                48\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 48, 'min_encoder_length': 48, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [3, 12]\n",
            "\"grid_size\":                     3\n",
            "\"learning_rate\":                 0.0007079457843841378\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [4, 4]\n",
            "\"num_blocks\":                    [2, 2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"spline_order\":                  3\n",
            "\"stack_types\":                   ['trend', 'seasonality']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64, 64]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 362 K  | train\n",
            "-------------------------------------------------------\n",
            "362 K     Trainable params\n",
            "0         Non-trainable params\n",
            "362 K     Total params\n",
            "1.449     Total estimated model params size (MB)\n",
            "49        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 20984/20984 [18:30<00:00, 18.90it/s, v_num=ed_1, train_loss_step=0.0537]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:06, 23.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:05, 23.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 23.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 23.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 23.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:05<00:02, 23.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:06<00:01, 23.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 23.29it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 23.22it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 23.23it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1: 100% 20984/20984 [19:20<00:00, 18.08it/s, v_num=ed_1, train_loss_step=0.0784, val_loss=0.0624, train_loss_epoch=0.0723]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 22.31it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.28it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.33it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.35it/s]\u001b[A\n",
            "Epoch 2: 100% 20984/20984 [19:15<00:00, 18.16it/s, v_num=ed_1, train_loss_step=0.0944, val_loss=0.0624, train_loss_epoch=0.0723]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.27it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.37it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.47it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.52it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.55it/s]\u001b[A\n",
            "Epoch 3: 100% 20984/20984 [19:14<00:00, 18.18it/s, v_num=ed_1, train_loss_step=0.106, val_loss=0.0624, train_loss_epoch=0.0723] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.15it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.48it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.63it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.72it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 22.03it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 22.05it/s]\u001b[A\n",
            "Epoch 4:  23% 4920/20984 [04:39<15:12, 17.61it/s, v_num=ed_1, train_loss_step=0.0965, val_loss=0.0624, train_loss_epoch=0.0723]\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
            "Epoch 4:  23% 4920/20984 [04:41<15:19, 17.48it/s, v_num=ed_1, train_loss_step=0.0965, val_loss=0.0624, train_loss_epoch=0.0723]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/KAN_BEATS/ECL_interp.py"
      ],
      "metadata": {
        "id": "MYrCwuBCRYQq",
        "outputId": "9a971ca8-b9e7-4e43-a689-69c8b754a6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "257774  21038  0.377660   9\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "\n",
            "[210430 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21043   21043  0.051095   0\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "...       ...       ...  ..\n",
            "260404  23668  0.196809   9\n",
            "260405  23669  0.199468   9\n",
            "260406  23670  0.199468   9\n",
            "260407  23671  0.091755   9\n",
            "260408  23672  0.117021   9\n",
            "\n",
            "[26300 rows x 3 columns]\n",
            "        index  variable  id\n",
            "23673   23673  0.467153   0\n",
            "23674   23674  0.452555   0\n",
            "23675   23675  0.437956   0\n",
            "23676   23676  0.664234   0\n",
            "23677   23677  0.452555   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[26310 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 20984 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "   | Name                                      | Type                  | Params | Mode \n",
            "---------------------------------------------------------------------------------------------\n",
            "0  | loss                                      | MAE                   | 0      | train\n",
            "1  | logging_metrics                           | ModuleList            | 0      | train\n",
            "2  | logging_metrics.0                         | SMAPE                 | 0      | train\n",
            "3  | logging_metrics.1                         | MAE                   | 0      | train\n",
            "4  | logging_metrics.2                         | RMSE                  | 0      | train\n",
            "5  | logging_metrics.3                         | MAPE                  | 0      | train\n",
            "6  | logging_metrics.4                         | MASE                  | 0      | train\n",
            "7  | logging_metrics.5                         | customR2Score         | 0      | train\n",
            "8  | net_blocks                                | ModuleList            | 231 K  | train\n",
            "9  | net_blocks.0                              | KANBEATSTrendBlock    | 57.5 K | train\n",
            "10 | net_blocks.0.kan                          | eff_KAN               | 57.3 K | train\n",
            "11 | net_blocks.0.kan.layers                   | ModuleList            | 57.3 K | train\n",
            "12 | net_blocks.0.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "13 | net_blocks.0.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "14 | net_blocks.0.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "15 | net_blocks.0.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "16 | net_blocks.0.theta_f_fc                   | Linear                | 192    | train\n",
            "17 | net_blocks.1                              | KANBEATSTrendBlock    | 57.5 K | train\n",
            "18 | net_blocks.1.kan                          | eff_KAN               | 57.3 K | train\n",
            "19 | net_blocks.1.kan.layers                   | ModuleList            | 57.3 K | train\n",
            "20 | net_blocks.1.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "21 | net_blocks.1.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "22 | net_blocks.1.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "23 | net_blocks.1.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "24 | net_blocks.1.theta_f_fc                   | Linear                | 192    | train\n",
            "25 | net_blocks.2                              | KANBEATSSeasonalBlock | 58.1 K | train\n",
            "26 | net_blocks.2.kan                          | eff_KAN               | 57.3 K | train\n",
            "27 | net_blocks.2.kan.layers                   | ModuleList            | 57.3 K | train\n",
            "28 | net_blocks.2.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "29 | net_blocks.2.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "30 | net_blocks.2.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "31 | net_blocks.2.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "32 | net_blocks.2.theta_f_fc                   | Linear                | 768    | train\n",
            "33 | net_blocks.3                              | KANBEATSSeasonalBlock | 58.1 K | train\n",
            "34 | net_blocks.3.kan                          | eff_KAN               | 57.3 K | train\n",
            "35 | net_blocks.3.kan.layers                   | ModuleList            | 57.3 K | train\n",
            "36 | net_blocks.3.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "37 | net_blocks.3.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "38 | net_blocks.3.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "39 | net_blocks.3.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "40 | net_blocks.3.theta_f_fc                   | Linear                | 768    | train\n",
            "---------------------------------------------------------------------------------------------\n",
            "231 K     Trainable params\n",
            "0         Non-trainable params\n",
            "231 K     Total params\n",
            "0.925     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/content/EasyTSF/easytsf/model/KAN_BEATS.py:1228: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  91% 91/100 [00:04<00:00, 21.76it/s]\n",
            "LR finder stopped early after 91 steps due to diverging loss.\n",
            "Learning rate set to 1.1220184543019633e-06\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_47d8c6d5-4570-4b7b-8a49-ac0cddfdb555.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_47d8c6d5-4570-4b7b-8a49-ac0cddfdb555.ckpt\n",
            "suggested learning rate: 1.1220184543019633e-06\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                48\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 48, 'min_encoder_length': 48, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [3, 12]\n",
            "\"grid_size\":                     3\n",
            "\"learning_rate\":                 1.1220184543019633e-06\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [3, 3]\n",
            "\"num_blocks\":                    [2, 2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"spline_order\":                  3\n",
            "\"stack_types\":                   ['trend', 'seasonality']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64, 64]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 231 K  | train\n",
            "-------------------------------------------------------\n",
            "231 K     Trainable params\n",
            "0         Non-trainable params\n",
            "231 K     Total params\n",
            "0.925     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 20984/20984 [14:29<00:00, 24.14it/s, v_num=ed_1, train_loss_step=0.0314]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.85it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.63it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.25it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.38it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.38it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1: 100% 20984/20984 [14:49<00:00, 23.58it/s, v_num=ed_1, train_loss_step=0.0518, val_loss=0.0518, train_loss_epoch=0.0606]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.09it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.16it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 22.19it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 22.24it/s]\u001b[A\n",
            "Epoch 2: 100% 20984/20984 [14:58<00:00, 23.34it/s, v_num=ed_1, train_loss_step=0.0646, val_loss=0.0505, train_loss_epoch=0.0522]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.35it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.36it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.42it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.54it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.58it/s]\u001b[A\n",
            "Epoch 3: 100% 20984/20984 [14:55<00:00, 23.42it/s, v_num=ed_1, train_loss_step=0.0607, val_loss=0.0509, train_loss_epoch=0.0519]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 20.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.56it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.01it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 22.10it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 22.14it/s]\u001b[A\n",
            "Epoch 4: 100% 20984/20984 [14:53<00:00, 23.50it/s, v_num=ed_1, train_loss_step=0.0625, val_loss=0.0516, train_loss_epoch=0.0528]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.55it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.79it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.11it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 22.18it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 22.21it/s]\u001b[A\n",
            "Epoch 5: 100% 20984/20984 [14:55<00:00, 23.43it/s, v_num=ed_1, train_loss_step=0.0489, val_loss=0.052, train_loss_epoch=0.0537]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.37it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.61it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.60it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.73it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.80it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.81it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.80it/s]\u001b[A\n",
            "Epoch 6: 100% 20984/20984 [14:58<00:00, 23.37it/s, v_num=ed_1, train_loss_step=0.100, val_loss=0.0521, train_loss_epoch=0.0541] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.20it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.15it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.02it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.91it/s]\u001b[A\n",
            "Epoch 7:   8% 1580/20984 [01:10<14:26, 22.40it/s, v_num=ed_1, train_loss_step=0.0667, val_loss=0.052, train_loss_epoch=0.054]\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
            "Epoch 7:   8% 1580/20984 [01:11<14:37, 22.10it/s, v_num=ed_1, train_loss_step=0.0667, val_loss=0.052, train_loss_epoch=0.054]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### По 3 слоя из 16 нейронов"
      ],
      "metadata": {
        "id": "GZbPcFi-kiBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/KAN_BEATS/ECL_interp.py"
      ],
      "metadata": {
        "id": "g7OMxkW5ur7V",
        "outputId": "e6c55908-2d71-4fa4-dd50-c57b072c14e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "{'hist_len': 48, 'pred_len': 12, 'batch_size': 128, 'max_epochs': 10, 'lr': 0.0001, 'optimizer': 'AdamW', 'optimizer_betas': (0.95, 0.9), 'optimizer_weight_decay': 1e-05, 'lr_scheduler': 'StepLR', 'lr_step_size': 1, 'lr_gamma': 0.5, 'gradient_clip_val': 5, 'val_metric': 'val_loss', 'test_metric': 'test_mae', 'es_patience': 10, 'norm_variable': True, 'norm_time_feature': False, 'include_time_feature': False, 'time_feature_cls': ['tod', 'dow'], 'file_format': 'csv', 'num_workers': 2, 'dataset_name': 'ECL', 'var_num': 321, 'freq': 60, 'data_split': [21043, 2630, 2631], 'model_name': 'KAN_BEATS', 'var_cut': 10, 'batch_sampler': 'synchronized', 'grid_size': 3, 'spline_order': 3, 'stack_types': ['trend', 'seasonality'], 'num_blocks': [2, 2], 'num_block_layers': [3, 3], 'widths': [16, 16], 'sharing': False, 'expansion_coefficient_lengths': [3, 12], 'backcast_loss_ratio': 0.1, 'loss': MAE(), 'log_interval': 10, 'log_gradient_flow': False, 'weight_decay': 0.01, 'learning_rate': 0.0001, 'reduce_on_plateau_patience': 10, 'seed': 1, 'data_root': 'drive/MyDrive/VKR/Data/Time series', 'save_root': 'drive/MyDrive/VKR/Results/save', 'devices': 'auto', 'use_wandb': 0, 'exp_time': '270525_0119', 'exp_dir': 'drive/MyDrive/VKR/Results/save/KAN_BEATS_ECL/270525_0119/seed_1'}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "257774  21038  0.377660   9\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "\n",
            "[210430 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21043   21043  0.051095   0\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "...       ...       ...  ..\n",
            "260404  23668  0.196809   9\n",
            "260405  23669  0.199468   9\n",
            "260406  23670  0.199468   9\n",
            "260407  23671  0.091755   9\n",
            "260408  23672  0.117021   9\n",
            "\n",
            "[26300 rows x 3 columns]\n",
            "        index  variable  id\n",
            "23673   23673  0.467153   0\n",
            "23674   23674  0.452555   0\n",
            "23675   23675  0.437956   0\n",
            "23676   23676  0.664234   0\n",
            "23677   23677  0.452555   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[26310 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 20984 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "   | Name                                      | Type                  | Params | Mode \n",
            "---------------------------------------------------------------------------------------------\n",
            "0  | loss                                      | MAE                   | 0      | train\n",
            "1  | logging_metrics                           | ModuleList            | 0      | train\n",
            "2  | logging_metrics.0                         | SMAPE                 | 0      | train\n",
            "3  | logging_metrics.1                         | MAE                   | 0      | train\n",
            "4  | logging_metrics.2                         | RMSE                  | 0      | train\n",
            "5  | logging_metrics.3                         | MAPE                  | 0      | train\n",
            "6  | logging_metrics.4                         | MASE                  | 0      | train\n",
            "7  | logging_metrics.5                         | customR2Score         | 0      | train\n",
            "8  | net_blocks                                | ModuleList            | 33.2 K | train\n",
            "9  | net_blocks.0                              | KANBEATSTrendBlock    | 8.2 K  | train\n",
            "10 | net_blocks.0.kan                          | eff_KAN               | 8.2 K  | train\n",
            "11 | net_blocks.0.kan.layers                   | ModuleList            | 8.2 K  | train\n",
            "12 | net_blocks.0.kan.layers.0                 | KANLinear             | 6.1 K  | train\n",
            "13 | net_blocks.0.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "14 | net_blocks.0.kan.layers.1                 | KANLinear             | 2.0 K  | train\n",
            "15 | net_blocks.0.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "16 | net_blocks.0.theta_f_fc                   | Linear                | 48     | train\n",
            "17 | net_blocks.1                              | KANBEATSTrendBlock    | 8.2 K  | train\n",
            "18 | net_blocks.1.kan                          | eff_KAN               | 8.2 K  | train\n",
            "19 | net_blocks.1.kan.layers                   | ModuleList            | 8.2 K  | train\n",
            "20 | net_blocks.1.kan.layers.0                 | KANLinear             | 6.1 K  | train\n",
            "21 | net_blocks.1.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "22 | net_blocks.1.kan.layers.1                 | KANLinear             | 2.0 K  | train\n",
            "23 | net_blocks.1.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "24 | net_blocks.1.theta_f_fc                   | Linear                | 48     | train\n",
            "25 | net_blocks.2                              | KANBEATSSeasonalBlock | 8.4 K  | train\n",
            "26 | net_blocks.2.kan                          | eff_KAN               | 8.2 K  | train\n",
            "27 | net_blocks.2.kan.layers                   | ModuleList            | 8.2 K  | train\n",
            "28 | net_blocks.2.kan.layers.0                 | KANLinear             | 6.1 K  | train\n",
            "29 | net_blocks.2.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "30 | net_blocks.2.kan.layers.1                 | KANLinear             | 2.0 K  | train\n",
            "31 | net_blocks.2.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "32 | net_blocks.2.theta_f_fc                   | Linear                | 192    | train\n",
            "33 | net_blocks.3                              | KANBEATSSeasonalBlock | 8.4 K  | train\n",
            "34 | net_blocks.3.kan                          | eff_KAN               | 8.2 K  | train\n",
            "35 | net_blocks.3.kan.layers                   | ModuleList            | 8.2 K  | train\n",
            "36 | net_blocks.3.kan.layers.0                 | KANLinear             | 6.1 K  | train\n",
            "37 | net_blocks.3.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "38 | net_blocks.3.kan.layers.1                 | KANLinear             | 2.0 K  | train\n",
            "39 | net_blocks.3.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "40 | net_blocks.3.theta_f_fc                   | Linear                | 192    | train\n",
            "---------------------------------------------------------------------------------------------\n",
            "33.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "33.2 K    Total params\n",
            "0.133     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/content/EasyTSF/easytsf/model/KAN_BEATS.py:1228: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  90% 90/100 [00:04<00:00, 22.03it/s]\n",
            "LR finder stopped early after 90 steps due to diverging loss.\n",
            "Learning rate set to 5.623413251903491e-05\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_0c912404-53c3-4295-b2b1-0f03a5fb46af.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_0c912404-53c3-4295-b2b1-0f03a5fb46af.ckpt\n",
            "suggested learning rate: 5.623413251903491e-05\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                48\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 48, 'min_encoder_length': 48, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [3, 12]\n",
            "\"grid_size\":                     3\n",
            "\"learning_rate\":                 5.623413251903491e-05\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [3, 3]\n",
            "\"num_blocks\":                    [2, 2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"spline_order\":                  3\n",
            "\"stack_types\":                   ['trend', 'seasonality']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [16, 16]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 33.2 K | train\n",
            "-------------------------------------------------------\n",
            "33.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "33.2 K    Total params\n",
            "0.133     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 20984/20984 [14:19<00:00, 24.40it/s, v_num=ed_1, train_loss_step=0.0369]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 22.95it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.33it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.65it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.73it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.95it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:06<00:01, 23.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 23.13it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 23.22it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 23.22it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1: 100% 20984/20984 [14:41<00:00, 23.80it/s, v_num=ed_1, train_loss_step=0.0581, val_loss=0.0509, train_loss_epoch=0.0548]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.45it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.79it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.00it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.90it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.88it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:01, 20.69it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 20.83it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 20.88it/s]\u001b[A\n",
            "Epoch 2: 100% 20984/20984 [14:45<00:00, 23.69it/s, v_num=ed_1, train_loss_step=0.0616, val_loss=0.0507, train_loss_epoch=0.0516]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.48it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.45it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 22.57it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.58it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.63it/s]\u001b[A\n",
            "Epoch 3: 100% 20984/20984 [14:49<00:00, 23.60it/s, v_num=ed_1, train_loss_step=0.0511, val_loss=0.0506, train_loss_epoch=0.0515]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 24.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:06, 24.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 23.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.73it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 22.83it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.80it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.83it/s]\u001b[A\n",
            "Epoch 4: 100% 20984/20984 [14:45<00:00, 23.69it/s, v_num=ed_1, train_loss_step=0.0592, val_loss=0.0506, train_loss_epoch=0.0514]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 23.00it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 23.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 23.15it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 23.26it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 23.18it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:06<00:01, 23.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 22.98it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.93it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.97it/s]\u001b[A\n",
            "Epoch 5: 100% 20984/20984 [14:55<00:00, 23.43it/s, v_num=ed_1, train_loss_step=0.0475, val_loss=0.0506, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 22.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.86it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.65it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.62it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.60it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.36it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.42it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.45it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.49it/s]\u001b[A\n",
            "Epoch 6: 100% 20984/20984 [14:50<00:00, 23.57it/s, v_num=ed_1, train_loss_step=0.0855, val_loss=0.0505, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 22.94it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.57it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.31it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.46it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.46it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.49it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.53it/s]\u001b[A\n",
            "Epoch 7: 100% 20984/20984 [14:57<00:00, 23.38it/s, v_num=ed_1, train_loss_step=0.036, val_loss=0.0506, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 20.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.89it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.97it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.94it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.94it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.98it/s]\u001b[A\n",
            "Epoch 8: 100% 20984/20984 [14:51<00:00, 23.53it/s, v_num=ed_1, train_loss_step=0.0558, val_loss=0.0506, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.35it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:06, 23.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 23.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 23.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 22.65it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.62it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.67it/s]\u001b[A\n",
            "Epoch 9: 100% 20984/20984 [14:51<00:00, 23.53it/s, v_num=ed_1, train_loss_step=0.0567, val_loss=0.0506, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.61it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.27it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.35it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.44it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.48it/s]\u001b[A\n",
            "Epoch 9: 100% 20984/20984 [15:01<00:00, 23.28it/s, v_num=ed_1, train_loss_step=0.0567, val_loss=0.0505, train_loss_epoch=0.0513]`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "Epoch 9: 100% 20984/20984 [15:11<00:00, 23.02it/s, v_num=ed_1, train_loss_step=0.0567, val_loss=0.0505, train_loss_epoch=0.0513]\n",
            "Training time: 9069.723 s (151.162 min, 2.519 h)\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/KAN_BEATS_ECL/270525_0119/seed_1/checkpoints/epoch=5-step=125904.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at drive/MyDrive/VKR/Results/save/KAN_BEATS_ECL/270525_0119/seed_1/checkpoints/epoch=5-step=125904.ckpt\n",
            "Testing DataLoader 0: 100% 201/201 [00:07<00:00, 25.78it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045118432492017746   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     4297.1982421875     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MASE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3374748229980469    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_RMSE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06181374937295914   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16434329748153687   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m   test_customR2Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00023527351731900126  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045118432492017746   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_backcast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0015912732342258096  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_forecast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045118432492017746   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 слоя по 10"
      ],
      "metadata": {
        "id": "tDhPjkhY_Oi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/KAN_BEATS/ECL_interp.py"
      ],
      "metadata": {
        "id": "Aqfs0pF76now",
        "outputId": "3787fada-1714-4324-9825-b0eea2d30a26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "257774  21038  0.377660   9\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "\n",
            "[210430 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21043   21043  0.051095   0\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "...       ...       ...  ..\n",
            "260404  23668  0.196809   9\n",
            "260405  23669  0.199468   9\n",
            "260406  23670  0.199468   9\n",
            "260407  23671  0.091755   9\n",
            "260408  23672  0.117021   9\n",
            "\n",
            "[26300 rows x 3 columns]\n",
            "        index  variable  id\n",
            "23673   23673  0.467153   0\n",
            "23674   23674  0.452555   0\n",
            "23675   23675  0.437956   0\n",
            "23676   23676  0.664234   0\n",
            "23677   23677  0.452555   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[26310 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 64 samples available for 20984 prediction times. Use batch size smaller than 64. First 10 prediction times with small batch sizes: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "   | Name                                      | Type                  | Params | Mode \n",
            "---------------------------------------------------------------------------------------------\n",
            "0  | loss                                      | MAE                   | 0      | train\n",
            "1  | logging_metrics                           | ModuleList            | 0      | train\n",
            "2  | logging_metrics.0                         | SMAPE                 | 0      | train\n",
            "3  | logging_metrics.1                         | MAE                   | 0      | train\n",
            "4  | logging_metrics.2                         | RMSE                  | 0      | train\n",
            "5  | logging_metrics.3                         | MAPE                  | 0      | train\n",
            "6  | logging_metrics.4                         | MASE                  | 0      | train\n",
            "7  | logging_metrics.5                         | customR2Score         | 0      | train\n",
            "8  | net_blocks                                | ModuleList            | 18.9 K | train\n",
            "9  | net_blocks.0                              | KANBEATSTrendBlock    | 4.7 K  | train\n",
            "10 | net_blocks.0.kan                          | eff_KAN               | 4.6 K  | train\n",
            "11 | net_blocks.0.kan.layers                   | ModuleList            | 4.6 K  | train\n",
            "12 | net_blocks.0.kan.layers.0                 | KANLinear             | 3.8 K  | train\n",
            "13 | net_blocks.0.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "14 | net_blocks.0.kan.layers.1                 | KANLinear             | 800    | train\n",
            "15 | net_blocks.0.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "16 | net_blocks.0.theta_f_fc                   | Linear                | 30     | train\n",
            "17 | net_blocks.1                              | KANBEATSTrendBlock    | 4.7 K  | train\n",
            "18 | net_blocks.1.kan                          | eff_KAN               | 4.6 K  | train\n",
            "19 | net_blocks.1.kan.layers                   | ModuleList            | 4.6 K  | train\n",
            "20 | net_blocks.1.kan.layers.0                 | KANLinear             | 3.8 K  | train\n",
            "21 | net_blocks.1.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "22 | net_blocks.1.kan.layers.1                 | KANLinear             | 800    | train\n",
            "23 | net_blocks.1.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "24 | net_blocks.1.theta_f_fc                   | Linear                | 30     | train\n",
            "25 | net_blocks.2                              | KANBEATSSeasonalBlock | 4.8 K  | train\n",
            "26 | net_blocks.2.kan                          | eff_KAN               | 4.6 K  | train\n",
            "27 | net_blocks.2.kan.layers                   | ModuleList            | 4.6 K  | train\n",
            "28 | net_blocks.2.kan.layers.0                 | KANLinear             | 3.8 K  | train\n",
            "29 | net_blocks.2.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "30 | net_blocks.2.kan.layers.1                 | KANLinear             | 800    | train\n",
            "31 | net_blocks.2.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "32 | net_blocks.2.theta_f_fc                   | Linear                | 120    | train\n",
            "33 | net_blocks.3                              | KANBEATSSeasonalBlock | 4.8 K  | train\n",
            "34 | net_blocks.3.kan                          | eff_KAN               | 4.6 K  | train\n",
            "35 | net_blocks.3.kan.layers                   | ModuleList            | 4.6 K  | train\n",
            "36 | net_blocks.3.kan.layers.0                 | KANLinear             | 3.8 K  | train\n",
            "37 | net_blocks.3.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "38 | net_blocks.3.kan.layers.1                 | KANLinear             | 800    | train\n",
            "39 | net_blocks.3.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "40 | net_blocks.3.theta_f_fc                   | Linear                | 120    | train\n",
            "---------------------------------------------------------------------------------------------\n",
            "18.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "18.9 K    Total params\n",
            "0.075     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/content/EasyTSF/easytsf/model/KAN_BEATS.py:1228: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  96% 96/100 [00:04<00:00, 23.15it/s]\n",
            "LR finder stopped early after 96 steps due to diverging loss.\n",
            "Learning rate set to 7.943282347242813e-06\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_e0747fbb-6a47-4f64-8538-50968b04b7ec.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_e0747fbb-6a47-4f64-8538-50968b04b7ec.ckpt\n",
            "suggested learning rate: 7.943282347242813e-06\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                48\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 48, 'min_encoder_length': 48, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [3, 12]\n",
            "\"grid_size\":                     3\n",
            "\"learning_rate\":                 7.943282347242813e-06\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [3, 3]\n",
            "\"num_blocks\":                    [2, 2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"spline_order\":                  3\n",
            "\"stack_types\":                   ['trend', 'seasonality']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [10, 10]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 18.9 K | train\n",
            "-------------------------------------------------------\n",
            "18.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "18.9 K    Total params\n",
            "0.075     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 20984/20984 [14:07<00:00, 24.76it/s, v_num=ed_1, train_loss_step=0.0365]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 34.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:10, 35.36it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:09, 35.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 35.58it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 35.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:07, 35.34it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:03<00:07, 35.32it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:06, 35.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 35.35it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 35.31it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 35.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:06<00:04, 35.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 35.32it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:07<00:03, 35.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 35.22it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 35.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 35.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 35.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:10<00:00, 35.26it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 35.22it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 35.22it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1: 100% 20984/20984 [14:42<00:00, 23.78it/s, v_num=ed_1, train_loss_step=0.0575, val_loss=0.0522, train_loss_epoch=0.0604]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 32.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:11, 32.64it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:10, 32.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 32.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:03<00:09, 33.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 33.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:04<00:07, 33.28it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:07, 33.46it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 33.56it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 33.71it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 33.85it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:07<00:04, 33.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 34.09it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:08<00:03, 34.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 34.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 34.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 34.32it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 34.36it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:11<00:00, 34.44it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 34.48it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 34.48it/s]\u001b[A\n",
            "Epoch 2: 100% 20984/20984 [14:40<00:00, 23.82it/s, v_num=ed_1, train_loss_step=0.0612, val_loss=0.052, train_loss_epoch=0.0541]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 33.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:10, 33.65it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:10, 33.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 33.97it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 34.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 34.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:04<00:07, 34.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:07, 34.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 34.04it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 34.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 34.16it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:07<00:04, 34.25it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 34.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:08<00:03, 34.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 34.22it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 34.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 34.10it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 33.88it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:11<00:00, 33.91it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 33.93it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 33.94it/s]\u001b[A\n",
            "Epoch 3: 100% 20984/20984 [14:39<00:00, 23.85it/s, v_num=ed_1, train_loss_step=0.0532, val_loss=0.0516, train_loss_epoch=0.0535]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 34.16it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:10, 34.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:09, 34.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 35.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 35.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 35.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:03<00:07, 35.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:06, 35.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 34.99it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 34.79it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 34.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:06<00:04, 34.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 34.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:08<00:03, 34.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 34.89it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 34.94it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 34.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 34.99it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:10<00:00, 34.96it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 34.90it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 34.90it/s]\u001b[A\n",
            "Epoch 4: 100% 20984/20984 [14:38<00:00, 23.88it/s, v_num=ed_1, train_loss_step=0.0601, val_loss=0.0513, train_loss_epoch=0.0528]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 32.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:10, 33.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:10, 33.79it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 34.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 33.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 33.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:04<00:07, 33.63it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:07, 33.85it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 34.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 34.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 34.16it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:07<00:04, 34.28it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 34.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:08<00:03, 34.46it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 34.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 34.60it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 34.58it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 34.62it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:10<00:00, 34.64it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 34.63it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 34.63it/s]\u001b[A\n",
            "Epoch 5: 100% 20984/20984 [14:43<00:00, 23.74it/s, v_num=ed_1, train_loss_step=0.0475, val_loss=0.051, train_loss_epoch=0.0522]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 33.16it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:10, 33.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:10, 33.88it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 33.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 34.04it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 34.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:04<00:07, 34.10it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:07, 34.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 34.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 34.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 34.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:07<00:04, 34.28it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 34.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:08<00:03, 33.99it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 34.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 34.10it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 34.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 34.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:11<00:00, 34.11it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 34.15it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 34.15it/s]\u001b[A\n",
            "Epoch 6: 100% 20984/20984 [14:40<00:00, 23.84it/s, v_num=ed_1, train_loss_step=0.0867, val_loss=0.0508, train_loss_epoch=0.0519]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:10, 35.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:10, 35.40it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:09, 35.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 35.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 34.58it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 34.56it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:04<00:07, 34.45it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:06, 34.62it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 34.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 34.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 34.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:06<00:04, 34.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 34.88it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:08<00:03, 34.88it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 34.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 34.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 34.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 34.97it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:10<00:00, 34.99it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 35.02it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 35.02it/s]\u001b[A\n",
            "Epoch 7: 100% 20984/20984 [14:43<00:00, 23.76it/s, v_num=ed_1, train_loss_step=0.0361, val_loss=0.0507, train_loss_epoch=0.0516]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 34.46it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:10, 34.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:09, 34.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 34.55it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 34.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 34.88it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:03<00:07, 35.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:06, 35.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 35.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 35.18it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 35.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:06<00:04, 35.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 35.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:07<00:03, 35.25it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 35.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 35.20it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 35.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 35.16it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:10<00:00, 35.14it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 35.04it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 35.03it/s]\u001b[A\n",
            "Epoch 8: 100% 20984/20984 [14:48<00:00, 23.62it/s, v_num=ed_1, train_loss_step=0.0552, val_loss=0.0506, train_loss_epoch=0.0515]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 33.37it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:10, 34.37it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:09, 34.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 34.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 34.76it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 34.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:04<00:07, 34.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:06, 34.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 34.79it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 34.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 34.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:06<00:04, 34.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 34.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:08<00:03, 34.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 34.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 34.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 34.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 34.60it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:11<00:00, 34.54it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 34.44it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 34.42it/s]\u001b[A\n",
            "Epoch 9: 100% 20984/20984 [14:53<00:00, 23.48it/s, v_num=ed_1, train_loss_step=0.0566, val_loss=0.0506, train_loss_epoch=0.0515]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/402 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/402 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 20/402 [00:00<00:11, 31.89it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 40/402 [00:01<00:11, 32.88it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 60/402 [00:01<00:10, 33.32it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 80/402 [00:02<00:09, 33.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 100/402 [00:02<00:08, 33.56it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 120/402 [00:03<00:08, 33.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 140/402 [00:04<00:07, 33.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 160/402 [00:04<00:07, 33.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 180/402 [00:05<00:06, 33.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 200/402 [00:05<00:05, 33.85it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 220/402 [00:06<00:05, 33.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 240/402 [00:07<00:04, 33.94it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 260/402 [00:07<00:04, 33.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 280/402 [00:08<00:03, 34.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 300/402 [00:08<00:02, 34.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 320/402 [00:09<00:02, 34.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 340/402 [00:09<00:01, 34.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 360/402 [00:10<00:01, 34.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 380/402 [00:11<00:00, 34.29it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 400/402 [00:11<00:00, 34.36it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 402/402 [00:11<00:00, 34.37it/s]\u001b[A\n",
            "Epoch 9: 100% 20984/20984 [15:06<00:00, 23.16it/s, v_num=ed_1, train_loss_step=0.0566, val_loss=0.0506, train_loss_epoch=0.0514]`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "Epoch 9: 100% 20984/20984 [15:16<00:00, 22.89it/s, v_num=ed_1, train_loss_step=0.0566, val_loss=0.0506, train_loss_epoch=0.0514]\n",
            "Training time: 9027.163 s (150.453 min, 2.508 h)\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/KAN_BEATS_ECL/270525_1258/seed_1/checkpoints/epoch=9-step=209840.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at drive/MyDrive/VKR/Results/save/KAN_BEATS_ECL/270525_1258/seed_1/checkpoints/epoch=9-step=209840.ckpt\n",
            "Testing DataLoader 0: 100% 402/402 [00:10<00:00, 36.62it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045203786343336105   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     4290.8955078125     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MASE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3403574228286743    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_RMSE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.061162009835243225   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16461889445781708   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m   test_customR2Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0004367830988485366  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045203786343336105   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_backcast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0015883048763498664  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_forecast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045203786343336105   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/KAN_BEATS/ECL_interp.py"
      ],
      "metadata": {
        "id": "6wmJKhhLusBD",
        "outputId": "b2b5f945-3d7a-469f-b2a1-4e5e3f45c53d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "257774  21038  0.377660   9\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "\n",
            "[210430 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21043   21043  0.051095   0\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "...       ...       ...  ..\n",
            "260404  23668  0.196809   9\n",
            "260405  23669  0.199468   9\n",
            "260406  23670  0.199468   9\n",
            "260407  23671  0.091755   9\n",
            "260408  23672  0.117021   9\n",
            "\n",
            "[26300 rows x 3 columns]\n",
            "        index  variable  id\n",
            "23673   23673  0.467153   0\n",
            "23674   23674  0.452555   0\n",
            "23675   23675  0.437956   0\n",
            "23676   23676  0.664234   0\n",
            "23677   23677  0.452555   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[26310 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 64 samples available for 20984 prediction times. Use batch size smaller than 64. First 10 prediction times with small batch sizes: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "   | Name                                      | Type                  | Params | Mode \n",
            "---------------------------------------------------------------------------------------------\n",
            "0  | loss                                      | MAE                   | 0      | train\n",
            "1  | logging_metrics                           | ModuleList            | 0      | train\n",
            "2  | logging_metrics.0                         | SMAPE                 | 0      | train\n",
            "3  | logging_metrics.1                         | MAE                   | 0      | train\n",
            "4  | logging_metrics.2                         | RMSE                  | 0      | train\n",
            "5  | logging_metrics.3                         | MAPE                  | 0      | train\n",
            "6  | logging_metrics.4                         | MASE                  | 0      | train\n",
            "7  | logging_metrics.5                         | customR2Score         | 0      | train\n",
            "8  | net_blocks                                | ModuleList            | 18.9 K | train\n",
            "9  | net_blocks.0                              | KANBEATSTrendBlock    | 4.7 K  | train\n",
            "10 | net_blocks.0.kan                          | eff_KAN               | 4.6 K  | train\n",
            "11 | net_blocks.0.kan.layers                   | ModuleList            | 4.6 K  | train\n",
            "12 | net_blocks.0.kan.layers.0                 | KANLinear             | 3.8 K  | train\n",
            "13 | net_blocks.0.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "14 | net_blocks.0.kan.layers.1                 | KANLinear             | 800    | train\n",
            "15 | net_blocks.0.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "16 | net_blocks.0.theta_f_fc                   | Linear                | 30     | train\n",
            "17 | net_blocks.1                              | KANBEATSTrendBlock    | 4.7 K  | train\n",
            "18 | net_blocks.1.kan                          | eff_KAN               | 4.6 K  | train\n",
            "19 | net_blocks.1.kan.layers                   | ModuleList            | 4.6 K  | train\n",
            "20 | net_blocks.1.kan.layers.0                 | KANLinear             | 3.8 K  | train\n",
            "21 | net_blocks.1.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "22 | net_blocks.1.kan.layers.1                 | KANLinear             | 800    | train\n",
            "23 | net_blocks.1.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "24 | net_blocks.1.theta_f_fc                   | Linear                | 30     | train\n",
            "25 | net_blocks.2                              | KANBEATSSeasonalBlock | 4.8 K  | train\n",
            "26 | net_blocks.2.kan                          | eff_KAN               | 4.6 K  | train\n",
            "27 | net_blocks.2.kan.layers                   | ModuleList            | 4.6 K  | train\n",
            "28 | net_blocks.2.kan.layers.0                 | KANLinear             | 3.8 K  | train\n",
            "29 | net_blocks.2.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "30 | net_blocks.2.kan.layers.1                 | KANLinear             | 800    | train\n",
            "31 | net_blocks.2.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "32 | net_blocks.2.theta_f_fc                   | Linear                | 120    | train\n",
            "33 | net_blocks.3                              | KANBEATSSeasonalBlock | 4.8 K  | train\n",
            "34 | net_blocks.3.kan                          | eff_KAN               | 4.6 K  | train\n",
            "35 | net_blocks.3.kan.layers                   | ModuleList            | 4.6 K  | train\n",
            "36 | net_blocks.3.kan.layers.0                 | KANLinear             | 3.8 K  | train\n",
            "37 | net_blocks.3.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "38 | net_blocks.3.kan.layers.1                 | KANLinear             | 800    | train\n",
            "39 | net_blocks.3.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "40 | net_blocks.3.theta_f_fc                   | Linear                | 120    | train\n",
            "---------------------------------------------------------------------------------------------\n",
            "18.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "18.9 K    Total params\n",
            "0.075     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/content/EasyTSF/easytsf/model/KAN_BEATS.py:1228: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr: 100% 100/100 [00:04<00:00, 23.19it/s]\n",
            "`Trainer.fit` stopped: `max_steps=100` reached.\n",
            "Learning rate set to 3.162277660168379e-09\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_12ce5fc7-ad91-4a1e-a79f-c43ca9814abf.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_12ce5fc7-ad91-4a1e-a79f-c43ca9814abf.ckpt\n",
            "suggested learning rate: 3.162277660168379e-09\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/EasyTSF/kan_beats_exp.py\", line 225, in <module>\n",
            "    train_func(training_conf, init_exp_conf)\n",
            "  File \"/content/EasyTSF/kan_beats_exp.py\", line 184, in train_func\n",
            "    fig = res.plot(show=True, suggest=True, ax=fig.axes)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/tuner/lr_finder.py\", line 160, in plot\n",
            "    fig = ax.figure\n",
            "          ^^^^^^^^^\n",
            "AttributeError: 'list' object has no attribute 'figure'\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-BEATS"
      ],
      "metadata": {
        "id": "Dvx6KZLZ9hJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/N_BEATS/ECL.py"
      ],
      "metadata": {
        "id": "Q69MJ_qV9i9j",
        "outputId": "7b5f3f9f-9954-47d0-81f1-dfbd8b0f6f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "255143  18407  0.365691   9\n",
            "255144  18408  0.324468   9\n",
            "255145  18409  0.293883   9\n",
            "255146  18410  0.285904   9\n",
            "255147  18411  0.265957   9\n",
            "\n",
            "[184120 rows x 3 columns]\n",
            "        index  variable  id\n",
            "18412   18412  0.087591   0\n",
            "18413   18413  0.087591   0\n",
            "18414   18414  0.080292   0\n",
            "18415   18415  0.080292   0\n",
            "18416   18416  0.102190   0\n",
            "...       ...       ...  ..\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "257779  21043  0.191489   9\n",
            "\n",
            "[26320 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "21048   21048  0.094891   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[52600 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 18377 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                24\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 24, 'min_encoder_length': 24, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [32]\n",
            "\"learning_rate\":                 0.001\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [2]\n",
            "\"num_blocks\":                    [2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"stack_types\":                   ['generic']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64]\n",
            "   | Name                     | Type               | Params | Mode \n",
            "-------------------------------------------------------------------------\n",
            "0  | loss                     | MAE                | 0      | train\n",
            "1  | logging_metrics          | ModuleList         | 0      | train\n",
            "2  | logging_metrics.0        | SMAPE              | 0      | train\n",
            "3  | logging_metrics.1        | MAE                | 0      | train\n",
            "4  | logging_metrics.2        | RMSE               | 0      | train\n",
            "5  | logging_metrics.3        | MAPE               | 0      | train\n",
            "6  | logging_metrics.4        | MASE               | 0      | train\n",
            "7  | net_blocks               | ModuleList         | 22.1 K | train\n",
            "8  | net_blocks.0             | NBEATSGenericBlock | 11.0 K | train\n",
            "9  | net_blocks.0.fc          | Sequential         | 5.8 K  | train\n",
            "10 | net_blocks.0.fc.0        | Linear             | 1.6 K  | train\n",
            "11 | net_blocks.0.fc.1        | ReLU               | 0      | train\n",
            "12 | net_blocks.0.fc.2        | Sequential         | 4.2 K  | train\n",
            "13 | net_blocks.0.fc.2.0      | Dropout            | 0      | train\n",
            "14 | net_blocks.0.fc.2.1      | Linear             | 4.2 K  | train\n",
            "15 | net_blocks.0.fc.3        | ReLU               | 0      | train\n",
            "16 | net_blocks.0.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "17 | net_blocks.0.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "18 | net_blocks.0.backcast_fc | Linear             | 792    | train\n",
            "19 | net_blocks.0.forecast_fc | Linear             | 396    | train\n",
            "20 | net_blocks.1             | NBEATSGenericBlock | 11.0 K | train\n",
            "21 | net_blocks.1.fc          | Sequential         | 5.8 K  | train\n",
            "22 | net_blocks.1.fc.0        | Linear             | 1.6 K  | train\n",
            "23 | net_blocks.1.fc.1        | ReLU               | 0      | train\n",
            "24 | net_blocks.1.fc.2        | Sequential         | 4.2 K  | train\n",
            "25 | net_blocks.1.fc.2.0      | Dropout            | 0      | train\n",
            "26 | net_blocks.1.fc.2.1      | Linear             | 4.2 K  | train\n",
            "27 | net_blocks.1.fc.3        | ReLU               | 0      | train\n",
            "28 | net_blocks.1.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "29 | net_blocks.1.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "30 | net_blocks.1.backcast_fc | Linear             | 792    | train\n",
            "31 | net_blocks.1.forecast_fc | Linear             | 396    | train\n",
            "-------------------------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "32        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 22.1 K | train\n",
            "-------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "32        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 18377/18377 [05:41<00:00, 53.84it/s, v_num=ed_1, train_loss_step=0.0685]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/203 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/203 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/203 [00:00<00:07, 22.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/203 [00:01<00:07, 23.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/203 [00:02<00:06, 23.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  39% 80/203 [00:03<00:05, 23.43it/s]\u001b[A\n",
            "Validation DataLoader 0:  49% 100/203 [00:04<00:04, 23.43it/s]\u001b[A\n",
            "Validation DataLoader 0:  59% 120/203 [00:05<00:03, 23.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  69% 140/203 [00:06<00:02, 23.22it/s]\u001b[A\n",
            "Validation DataLoader 0:  79% 160/203 [00:06<00:01, 23.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 180/203 [00:07<00:00, 23.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  99% 200/203 [00:08<00:00, 22.86it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 203/203 [00:08<00:00, 22.84it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 0: 100% 18377/18377 [05:50<00:00, 52.44it/s, v_num=ed_1, train_loss_step=0.0685, val_loss=0.0625, train_loss_epoch=0.0716]`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "Epoch 0: 100% 18377/18377 [05:52<00:00, 52.18it/s, v_num=ed_1, train_loss_step=0.0685, val_loss=0.0625, train_loss_epoch=0.0716]\n",
            "Training time: 356.432 s (5.941 min, 0.099 h)\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/N_BEATS_ECL/260525_1902/seed_1/checkpoints/epoch=0-step=18377.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at drive/MyDrive/VKR/Results/save/N_BEATS_ECL/260525_1902/seed_1/checkpoints/epoch=0-step=18377.ckpt\n",
            "Testing DataLoader 0: 100% 409/409 [00:16<00:00, 25.37it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06336717307567596   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      5546.01171875      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MASE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8850963115692139    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_RMSE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08142081648111343   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22307169437408447   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06336717307567596   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_backcast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.002776762703433633   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_forecast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06336717307567596   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С подбором lr"
      ],
      "metadata": {
        "id": "-8_FyXByXbfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/N_BEATS/ECL.py"
      ],
      "metadata": {
        "id": "SkQKOGhWXXOL",
        "outputId": "5ada4437-2f57-4557-977d-6555d99faee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "255143  18407  0.365691   9\n",
            "255144  18408  0.324468   9\n",
            "255145  18409  0.293883   9\n",
            "255146  18410  0.285904   9\n",
            "255147  18411  0.265957   9\n",
            "\n",
            "[184120 rows x 3 columns]\n",
            "        index  variable  id\n",
            "18412   18412  0.087591   0\n",
            "18413   18413  0.087591   0\n",
            "18414   18414  0.080292   0\n",
            "18415   18415  0.080292   0\n",
            "18416   18416  0.102190   0\n",
            "...       ...       ...  ..\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "257779  21043  0.191489   9\n",
            "\n",
            "[26320 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "21048   21048  0.094891   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[52600 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 18377 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                24\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 24, 'min_encoder_length': 24, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [32]\n",
            "\"learning_rate\":                 0.001\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [2]\n",
            "\"num_blocks\":                    [2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"stack_types\":                   ['generic']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64]\n",
            "   | Name                     | Type               | Params | Mode \n",
            "-------------------------------------------------------------------------\n",
            "0  | loss                     | MAE                | 0      | train\n",
            "1  | logging_metrics          | ModuleList         | 0      | train\n",
            "2  | logging_metrics.0        | SMAPE              | 0      | train\n",
            "3  | logging_metrics.1        | MAE                | 0      | train\n",
            "4  | logging_metrics.2        | RMSE               | 0      | train\n",
            "5  | logging_metrics.3        | MAPE               | 0      | train\n",
            "6  | logging_metrics.4        | MASE               | 0      | train\n",
            "7  | logging_metrics.5        | customR2Score      | 0      | train\n",
            "8  | net_blocks               | ModuleList         | 22.1 K | train\n",
            "9  | net_blocks.0             | NBEATSGenericBlock | 11.0 K | train\n",
            "10 | net_blocks.0.fc          | Sequential         | 5.8 K  | train\n",
            "11 | net_blocks.0.fc.0        | Linear             | 1.6 K  | train\n",
            "12 | net_blocks.0.fc.1        | ReLU               | 0      | train\n",
            "13 | net_blocks.0.fc.2        | Sequential         | 4.2 K  | train\n",
            "14 | net_blocks.0.fc.2.0      | Dropout            | 0      | train\n",
            "15 | net_blocks.0.fc.2.1      | Linear             | 4.2 K  | train\n",
            "16 | net_blocks.0.fc.3        | ReLU               | 0      | train\n",
            "17 | net_blocks.0.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "18 | net_blocks.0.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "19 | net_blocks.0.backcast_fc | Linear             | 792    | train\n",
            "20 | net_blocks.0.forecast_fc | Linear             | 396    | train\n",
            "21 | net_blocks.1             | NBEATSGenericBlock | 11.0 K | train\n",
            "22 | net_blocks.1.fc          | Sequential         | 5.8 K  | train\n",
            "23 | net_blocks.1.fc.0        | Linear             | 1.6 K  | train\n",
            "24 | net_blocks.1.fc.1        | ReLU               | 0      | train\n",
            "25 | net_blocks.1.fc.2        | Sequential         | 4.2 K  | train\n",
            "26 | net_blocks.1.fc.2.0      | Dropout            | 0      | train\n",
            "27 | net_blocks.1.fc.2.1      | Linear             | 4.2 K  | train\n",
            "28 | net_blocks.1.fc.3        | ReLU               | 0      | train\n",
            "29 | net_blocks.1.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "30 | net_blocks.1.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "31 | net_blocks.1.backcast_fc | Linear             | 792    | train\n",
            "32 | net_blocks.1.forecast_fc | Linear             | 396    | train\n",
            "-------------------------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "33        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/models/nbeats/_nbeats.py:375: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  99% 99/100 [00:02<00:00, 53.50it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
            "Finding best initial lr: 100% 100/100 [00:02<00:00, 48.47it/s]\n",
            "Learning rate set to 5.623413251903491e-05\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_fe424fdb-3192-4eef-b146-81c774b5f958.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_fe424fdb-3192-4eef-b146-81c774b5f958.ckpt\n",
            "suggested learning rate: 5.623413251903491e-05\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 22.1 K | train\n",
            "-------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "33        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 18377/18377 [05:46<00:00, 53.02it/s, v_num=ed_1, train_loss_step=0.0689]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/203 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/203 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/203 [00:00<00:07, 24.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/203 [00:01<00:06, 23.90it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/203 [00:02<00:06, 23.51it/s]\u001b[A\n",
            "Validation DataLoader 0:  39% 80/203 [00:03<00:05, 23.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  49% 100/203 [00:04<00:04, 23.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  59% 120/203 [00:05<00:03, 23.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  69% 140/203 [00:06<00:02, 23.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  79% 160/203 [00:06<00:01, 23.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 180/203 [00:07<00:00, 23.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  99% 200/203 [00:08<00:00, 23.10it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 203/203 [00:08<00:00, 23.07it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 0: 100% 18377/18377 [05:55<00:00, 51.67it/s, v_num=ed_1, train_loss_step=0.0689, val_loss=0.0624, train_loss_epoch=0.0719]`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "Epoch 0: 100% 18377/18377 [05:57<00:00, 51.41it/s, v_num=ed_1, train_loss_step=0.0689, val_loss=0.0624, train_loss_epoch=0.0719]\n",
            "Training time: 360.026 s (6.000 min, 0.100 h)\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/N_BEATS_ECL/260525_1912/seed_1/checkpoints/epoch=0-step=18377.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at drive/MyDrive/VKR/Results/save/N_BEATS_ECL/260525_1912/seed_1/checkpoints/epoch=0-step=18377.ckpt\n",
            "Testing DataLoader 0: 100% 409/409 [00:16<00:00, 25.39it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06329068541526794   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5491.01806640625     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MASE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8848509788513184    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_RMSE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08147545158863068   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2230139970779419    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m   test_customR2Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m -2.9475204428308643e-05 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06329068541526794   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_backcast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0027765827253460884  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_forecast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06329068541526794   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "График к предыдущему"
      ],
      "metadata": {
        "id": "lbsQtcMUY2Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/N_BEATS/ECL.py"
      ],
      "metadata": {
        "id": "OZa-DOqpYzC-",
        "outputId": "2f6388e9-3cad-4ff3-efb3-65cc505c3a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "255143  18407  0.365691   9\n",
            "255144  18408  0.324468   9\n",
            "255145  18409  0.293883   9\n",
            "255146  18410  0.285904   9\n",
            "255147  18411  0.265957   9\n",
            "\n",
            "[184120 rows x 3 columns]\n",
            "        index  variable  id\n",
            "18412   18412  0.087591   0\n",
            "18413   18413  0.087591   0\n",
            "18414   18414  0.080292   0\n",
            "18415   18415  0.080292   0\n",
            "18416   18416  0.102190   0\n",
            "...       ...       ...  ..\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "257779  21043  0.191489   9\n",
            "\n",
            "[26320 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "21048   21048  0.094891   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[52600 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 18377 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                24\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 24, 'min_encoder_length': 24, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [32]\n",
            "\"learning_rate\":                 0.001\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [2]\n",
            "\"num_blocks\":                    [2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"stack_types\":                   ['generic']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64]\n",
            "   | Name                     | Type               | Params | Mode \n",
            "-------------------------------------------------------------------------\n",
            "0  | loss                     | MAE                | 0      | train\n",
            "1  | logging_metrics          | ModuleList         | 0      | train\n",
            "2  | logging_metrics.0        | SMAPE              | 0      | train\n",
            "3  | logging_metrics.1        | MAE                | 0      | train\n",
            "4  | logging_metrics.2        | RMSE               | 0      | train\n",
            "5  | logging_metrics.3        | MAPE               | 0      | train\n",
            "6  | logging_metrics.4        | MASE               | 0      | train\n",
            "7  | logging_metrics.5        | customR2Score      | 0      | train\n",
            "8  | net_blocks               | ModuleList         | 22.1 K | train\n",
            "9  | net_blocks.0             | NBEATSGenericBlock | 11.0 K | train\n",
            "10 | net_blocks.0.fc          | Sequential         | 5.8 K  | train\n",
            "11 | net_blocks.0.fc.0        | Linear             | 1.6 K  | train\n",
            "12 | net_blocks.0.fc.1        | ReLU               | 0      | train\n",
            "13 | net_blocks.0.fc.2        | Sequential         | 4.2 K  | train\n",
            "14 | net_blocks.0.fc.2.0      | Dropout            | 0      | train\n",
            "15 | net_blocks.0.fc.2.1      | Linear             | 4.2 K  | train\n",
            "16 | net_blocks.0.fc.3        | ReLU               | 0      | train\n",
            "17 | net_blocks.0.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "18 | net_blocks.0.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "19 | net_blocks.0.backcast_fc | Linear             | 792    | train\n",
            "20 | net_blocks.0.forecast_fc | Linear             | 396    | train\n",
            "21 | net_blocks.1             | NBEATSGenericBlock | 11.0 K | train\n",
            "22 | net_blocks.1.fc          | Sequential         | 5.8 K  | train\n",
            "23 | net_blocks.1.fc.0        | Linear             | 1.6 K  | train\n",
            "24 | net_blocks.1.fc.1        | ReLU               | 0      | train\n",
            "25 | net_blocks.1.fc.2        | Sequential         | 4.2 K  | train\n",
            "26 | net_blocks.1.fc.2.0      | Dropout            | 0      | train\n",
            "27 | net_blocks.1.fc.2.1      | Linear             | 4.2 K  | train\n",
            "28 | net_blocks.1.fc.3        | ReLU               | 0      | train\n",
            "29 | net_blocks.1.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "30 | net_blocks.1.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "31 | net_blocks.1.backcast_fc | Linear             | 792    | train\n",
            "32 | net_blocks.1.forecast_fc | Linear             | 396    | train\n",
            "-------------------------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "33        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/models/nbeats/_nbeats.py:375: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  99% 99/100 [00:02<00:00, 45.50it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
            "Finding best initial lr: 100% 100/100 [00:02<00:00, 43.88it/s]\n",
            "Learning rate set to 5.623413251903491e-05\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_6644715f-fa30-49b7-a0a4-d8abad041c64.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_6644715f-fa30-49b7-a0a4-d8abad041c64.ckpt\n",
            "suggested learning rate: 5.623413251903491e-05\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ]
}