{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyObCy2uOr+8AsNMJ8V9u4XB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "36JZI-VE8C1e",
        "outputId": "3dbba6db-cf0f-46d2-a222-8b2445fe00a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EasyTSF'...\n",
            "remote: Enumerating objects: 705, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 705 (delta 84), reused 96 (delta 49), pack-reused 560 (from 2)\u001b[K\n",
            "Receiving objects: 100% (705/705), 1.87 MiB | 20.21 MiB/s, done.\n",
            "Resolving deltas: 100% (386/386), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Olyco/EasyTSF.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G6JkPFRy8LVA",
        "outputId": "2e103e87-5ad1-4cff-d8e6-7f97b6d706a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"EasyTSF/requirements.txt\""
      ],
      "metadata": {
        "id": "xuxMN9fT8L1h",
        "outputId": "e36adc67-38e0-4a8e-ad79-684b2647a47d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Brotli==1.0.9 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 1)) (1.0.9)\n",
            "Requirement already satisfied: certifi==2024.7.4 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 2)) (2024.7.4)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: filelock==3.13.1 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 5)) (3.13.1)\n",
            "Requirement already satisfied: fsspec==2024.6.1 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 6)) (2024.6.1)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: Jinja2==3.1.4 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: lightning==2.4.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 9)) (2.4.0)\n",
            "Requirement already satisfied: lightning-utilities==0.11.6 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 10)) (0.11.6)\n",
            "Requirement already satisfied: MarkupSafe==2.1.3 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 11)) (2.1.3)\n",
            "Requirement already satisfied: mkl-fft==1.3.8 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 12)) (1.3.8)\n",
            "Requirement already satisfied: mkl-random==1.2.4 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 13)) (1.2.4)\n",
            "Requirement already satisfied: mkl-service==2.4.1 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 14)) (2.4.1)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.3 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 16)) (3.3)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 17)) (1.26.4)\n",
            "Requirement already satisfied: packaging==24.1 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 18)) (24.1)\n",
            "Requirement already satisfied: pillow==10.4.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 19)) (10.4.0)\n",
            "Requirement already satisfied: pip==24.2 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 20)) (24.2)\n",
            "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 21)) (1.7.1)\n",
            "Requirement already satisfied: pytorch-lightning==2.4.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 22)) (2.4.0)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 23)) (6.0.1)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 24)) (2.32.3)\n",
            "Requirement already satisfied: setuptools==72.1.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 25)) (72.1.0)\n",
            "Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 26)) (1.12)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 27)) (2.4.0)\n",
            "Requirement already satisfied: torchaudio==2.4.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 28)) (2.4.0)\n",
            "Requirement already satisfied: torchmetrics==1.4.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 29)) (1.4.0.post0)\n",
            "Requirement already satisfied: torchvision==0.19.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 30)) (0.19.0)\n",
            "Requirement already satisfied: tqdm==4.66.5 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 31)) (4.66.5)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 32)) (3.0.0)\n",
            "Requirement already satisfied: typing_extensions==4.11.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 33)) (4.11.0)\n",
            "Requirement already satisfied: urllib3==2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 34)) (2.2.2)\n",
            "Requirement already satisfied: wheel==0.43.0 in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 35)) (0.43.0)\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 36)) (0.0.7)\n",
            "Requirement already satisfied: ray in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 37)) (2.46.0)\n",
            "Requirement already satisfied: pykan in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 38)) (0.2.8)\n",
            "Requirement already satisfied: pytorch_forecasting in /usr/local/lib/python3.11/dist-packages (from -r EasyTSF/requirements.txt (line 39)) (1.3.0)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (2025.0.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->-r EasyTSF/requirements.txt (line 27)) (12.5.82)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray->-r EasyTSF/requirements.txt (line 37)) (8.2.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray->-r EasyTSF/requirements.txt (line 37)) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray->-r EasyTSF/requirements.txt (line 37)) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray->-r EasyTSF/requirements.txt (line 37)) (5.29.4)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (1.15.3)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (1.6.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (3.11.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (3.6.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->-r EasyTSF/requirements.txt (line 37)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->-r EasyTSF/requirements.txt (line 37)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->-r EasyTSF/requirements.txt (line 37)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->-r EasyTSF/requirements.txt (line 37)) (0.24.0)\n",
            "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (2025.1.1)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (2022.1.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r EasyTSF/requirements.txt (line 9)) (1.20.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2025.1.1 in /usr/local/lib/python3.11/dist-packages (from intel-openmp>=2024->mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (2025.1.1)\n",
            "Requirement already satisfied: umf==0.10.* in /usr/local/lib/python3.11/dist-packages (from intel-cmplr-lib-ur==2025.1.1->intel-openmp>=2024->mkl->mkl-fft==1.3.8->-r EasyTSF/requirements.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch_forecasting->-r EasyTSF/requirements.txt (line 39)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KAN-BEATS"
      ],
      "metadata": {
        "id": "FWqAKSkS9dsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Интерпретируемый"
      ],
      "metadata": {
        "id": "9FE4BLNx9wRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По 48 часам прогноз на 12 часов, 10 переменных,\n",
        "num_blocks=[2, 2],\n",
        "num_block_layers=[4, 4],\n",
        "widths=[64, 64],\n",
        "sharing=False,\n",
        "expansion_coefficient_lengths=[3, 12]"
      ],
      "metadata": {
        "id": "4jTdXBxTdK7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/KAN_BEATS/ECL_interp.py"
      ],
      "metadata": {
        "id": "e7hKIGSI9gqT",
        "outputId": "aeab8250-9488-49d1-8348-4e6cdad02648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "257774  21038  0.377660   9\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "\n",
            "[210430 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21043   21043  0.051095   0\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "...       ...       ...  ..\n",
            "260404  23668  0.196809   9\n",
            "260405  23669  0.199468   9\n",
            "260406  23670  0.199468   9\n",
            "260407  23671  0.091755   9\n",
            "260408  23672  0.117021   9\n",
            "\n",
            "[26300 rows x 3 columns]\n",
            "        index  variable  id\n",
            "23673   23673  0.467153   0\n",
            "23674   23674  0.452555   0\n",
            "23675   23675  0.437956   0\n",
            "23676   23676  0.664234   0\n",
            "23677   23677  0.452555   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[26310 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 20984 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "   | Name                                      | Type                  | Params | Mode \n",
            "---------------------------------------------------------------------------------------------\n",
            "0  | loss                                      | MAE                   | 0      | train\n",
            "1  | logging_metrics                           | ModuleList            | 0      | train\n",
            "2  | logging_metrics.0                         | SMAPE                 | 0      | train\n",
            "3  | logging_metrics.1                         | MAE                   | 0      | train\n",
            "4  | logging_metrics.2                         | RMSE                  | 0      | train\n",
            "5  | logging_metrics.3                         | MAPE                  | 0      | train\n",
            "6  | logging_metrics.4                         | MASE                  | 0      | train\n",
            "7  | logging_metrics.5                         | customR2Score         | 0      | train\n",
            "8  | net_blocks                                | ModuleList            | 362 K  | train\n",
            "9  | net_blocks.0                              | KANBEATSTrendBlock    | 90.3 K | train\n",
            "10 | net_blocks.0.kan                          | eff_KAN               | 90.1 K | train\n",
            "11 | net_blocks.0.kan.layers                   | ModuleList            | 90.1 K | train\n",
            "12 | net_blocks.0.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "13 | net_blocks.0.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "14 | net_blocks.0.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "15 | net_blocks.0.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "16 | net_blocks.0.kan.layers.2                 | KANLinear             | 32.8 K | train\n",
            "17 | net_blocks.0.kan.layers.2.base_activation | SiLU                  | 0      | train\n",
            "18 | net_blocks.0.theta_f_fc                   | Linear                | 192    | train\n",
            "19 | net_blocks.1                              | KANBEATSTrendBlock    | 90.3 K | train\n",
            "20 | net_blocks.1.kan                          | eff_KAN               | 90.1 K | train\n",
            "21 | net_blocks.1.kan.layers                   | ModuleList            | 90.1 K | train\n",
            "22 | net_blocks.1.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "23 | net_blocks.1.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "24 | net_blocks.1.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "25 | net_blocks.1.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "26 | net_blocks.1.kan.layers.2                 | KANLinear             | 32.8 K | train\n",
            "27 | net_blocks.1.kan.layers.2.base_activation | SiLU                  | 0      | train\n",
            "28 | net_blocks.1.theta_f_fc                   | Linear                | 192    | train\n",
            "29 | net_blocks.2                              | KANBEATSSeasonalBlock | 90.9 K | train\n",
            "30 | net_blocks.2.kan                          | eff_KAN               | 90.1 K | train\n",
            "31 | net_blocks.2.kan.layers                   | ModuleList            | 90.1 K | train\n",
            "32 | net_blocks.2.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "33 | net_blocks.2.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "34 | net_blocks.2.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "35 | net_blocks.2.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "36 | net_blocks.2.kan.layers.2                 | KANLinear             | 32.8 K | train\n",
            "37 | net_blocks.2.kan.layers.2.base_activation | SiLU                  | 0      | train\n",
            "38 | net_blocks.2.theta_f_fc                   | Linear                | 768    | train\n",
            "39 | net_blocks.3                              | KANBEATSSeasonalBlock | 90.9 K | train\n",
            "40 | net_blocks.3.kan                          | eff_KAN               | 90.1 K | train\n",
            "41 | net_blocks.3.kan.layers                   | ModuleList            | 90.1 K | train\n",
            "42 | net_blocks.3.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "43 | net_blocks.3.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "44 | net_blocks.3.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "45 | net_blocks.3.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "46 | net_blocks.3.kan.layers.2                 | KANLinear             | 32.8 K | train\n",
            "47 | net_blocks.3.kan.layers.2.base_activation | SiLU                  | 0      | train\n",
            "48 | net_blocks.3.theta_f_fc                   | Linear                | 768    | train\n",
            "---------------------------------------------------------------------------------------------\n",
            "362 K     Trainable params\n",
            "0         Non-trainable params\n",
            "362 K     Total params\n",
            "1.449     Total estimated model params size (MB)\n",
            "49        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/content/EasyTSF/easytsf/model/KAN_BEATS.py:1228: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  98% 98/100 [00:05<00:00, 17.74it/s]\n",
            "LR finder stopped early after 98 steps due to diverging loss.\n",
            "Learning rate set to 0.0007079457843841378\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_fde12c81-6b15-4746-83f2-bb4dd2638f19.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_fde12c81-6b15-4746-83f2-bb4dd2638f19.ckpt\n",
            "suggested learning rate: 0.0007079457843841378\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                48\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 48, 'min_encoder_length': 48, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [3, 12]\n",
            "\"grid_size\":                     3\n",
            "\"learning_rate\":                 0.0007079457843841378\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [4, 4]\n",
            "\"num_blocks\":                    [2, 2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"spline_order\":                  3\n",
            "\"stack_types\":                   ['trend', 'seasonality']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64, 64]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 362 K  | train\n",
            "-------------------------------------------------------\n",
            "362 K     Trainable params\n",
            "0         Non-trainable params\n",
            "362 K     Total params\n",
            "1.449     Total estimated model params size (MB)\n",
            "49        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 20984/20984 [18:30<00:00, 18.90it/s, v_num=ed_1, train_loss_step=0.0537]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:06, 23.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:05, 23.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 23.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 23.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 23.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:05<00:02, 23.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:06<00:01, 23.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 23.29it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 23.22it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 23.23it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1: 100% 20984/20984 [19:20<00:00, 18.08it/s, v_num=ed_1, train_loss_step=0.0784, val_loss=0.0624, train_loss_epoch=0.0723]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 22.31it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.28it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.33it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.35it/s]\u001b[A\n",
            "Epoch 2: 100% 20984/20984 [19:15<00:00, 18.16it/s, v_num=ed_1, train_loss_step=0.0944, val_loss=0.0624, train_loss_epoch=0.0723]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.27it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.37it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.47it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.52it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.55it/s]\u001b[A\n",
            "Epoch 3: 100% 20984/20984 [19:14<00:00, 18.18it/s, v_num=ed_1, train_loss_step=0.106, val_loss=0.0624, train_loss_epoch=0.0723] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.15it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.48it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.63it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.72it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 22.03it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 22.05it/s]\u001b[A\n",
            "Epoch 4:  23% 4920/20984 [04:39<15:12, 17.61it/s, v_num=ed_1, train_loss_step=0.0965, val_loss=0.0624, train_loss_epoch=0.0723]\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
            "Epoch 4:  23% 4920/20984 [04:41<15:19, 17.48it/s, v_num=ed_1, train_loss_step=0.0965, val_loss=0.0624, train_loss_epoch=0.0723]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/KAN_BEATS/ECL_interp.py"
      ],
      "metadata": {
        "id": "MYrCwuBCRYQq",
        "outputId": "9a971ca8-b9e7-4e43-a689-69c8b754a6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "257774  21038  0.377660   9\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "\n",
            "[210430 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21043   21043  0.051095   0\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "...       ...       ...  ..\n",
            "260404  23668  0.196809   9\n",
            "260405  23669  0.199468   9\n",
            "260406  23670  0.199468   9\n",
            "260407  23671  0.091755   9\n",
            "260408  23672  0.117021   9\n",
            "\n",
            "[26300 rows x 3 columns]\n",
            "        index  variable  id\n",
            "23673   23673  0.467153   0\n",
            "23674   23674  0.452555   0\n",
            "23675   23675  0.437956   0\n",
            "23676   23676  0.664234   0\n",
            "23677   23677  0.452555   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[26310 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 20984 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "   | Name                                      | Type                  | Params | Mode \n",
            "---------------------------------------------------------------------------------------------\n",
            "0  | loss                                      | MAE                   | 0      | train\n",
            "1  | logging_metrics                           | ModuleList            | 0      | train\n",
            "2  | logging_metrics.0                         | SMAPE                 | 0      | train\n",
            "3  | logging_metrics.1                         | MAE                   | 0      | train\n",
            "4  | logging_metrics.2                         | RMSE                  | 0      | train\n",
            "5  | logging_metrics.3                         | MAPE                  | 0      | train\n",
            "6  | logging_metrics.4                         | MASE                  | 0      | train\n",
            "7  | logging_metrics.5                         | customR2Score         | 0      | train\n",
            "8  | net_blocks                                | ModuleList            | 231 K  | train\n",
            "9  | net_blocks.0                              | KANBEATSTrendBlock    | 57.5 K | train\n",
            "10 | net_blocks.0.kan                          | eff_KAN               | 57.3 K | train\n",
            "11 | net_blocks.0.kan.layers                   | ModuleList            | 57.3 K | train\n",
            "12 | net_blocks.0.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "13 | net_blocks.0.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "14 | net_blocks.0.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "15 | net_blocks.0.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "16 | net_blocks.0.theta_f_fc                   | Linear                | 192    | train\n",
            "17 | net_blocks.1                              | KANBEATSTrendBlock    | 57.5 K | train\n",
            "18 | net_blocks.1.kan                          | eff_KAN               | 57.3 K | train\n",
            "19 | net_blocks.1.kan.layers                   | ModuleList            | 57.3 K | train\n",
            "20 | net_blocks.1.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "21 | net_blocks.1.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "22 | net_blocks.1.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "23 | net_blocks.1.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "24 | net_blocks.1.theta_f_fc                   | Linear                | 192    | train\n",
            "25 | net_blocks.2                              | KANBEATSSeasonalBlock | 58.1 K | train\n",
            "26 | net_blocks.2.kan                          | eff_KAN               | 57.3 K | train\n",
            "27 | net_blocks.2.kan.layers                   | ModuleList            | 57.3 K | train\n",
            "28 | net_blocks.2.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "29 | net_blocks.2.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "30 | net_blocks.2.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "31 | net_blocks.2.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "32 | net_blocks.2.theta_f_fc                   | Linear                | 768    | train\n",
            "33 | net_blocks.3                              | KANBEATSSeasonalBlock | 58.1 K | train\n",
            "34 | net_blocks.3.kan                          | eff_KAN               | 57.3 K | train\n",
            "35 | net_blocks.3.kan.layers                   | ModuleList            | 57.3 K | train\n",
            "36 | net_blocks.3.kan.layers.0                 | KANLinear             | 24.6 K | train\n",
            "37 | net_blocks.3.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "38 | net_blocks.3.kan.layers.1                 | KANLinear             | 32.8 K | train\n",
            "39 | net_blocks.3.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "40 | net_blocks.3.theta_f_fc                   | Linear                | 768    | train\n",
            "---------------------------------------------------------------------------------------------\n",
            "231 K     Trainable params\n",
            "0         Non-trainable params\n",
            "231 K     Total params\n",
            "0.925     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/content/EasyTSF/easytsf/model/KAN_BEATS.py:1228: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  91% 91/100 [00:04<00:00, 21.76it/s]\n",
            "LR finder stopped early after 91 steps due to diverging loss.\n",
            "Learning rate set to 1.1220184543019633e-06\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_47d8c6d5-4570-4b7b-8a49-ac0cddfdb555.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_47d8c6d5-4570-4b7b-8a49-ac0cddfdb555.ckpt\n",
            "suggested learning rate: 1.1220184543019633e-06\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                48\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 48, 'min_encoder_length': 48, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [3, 12]\n",
            "\"grid_size\":                     3\n",
            "\"learning_rate\":                 1.1220184543019633e-06\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [3, 3]\n",
            "\"num_blocks\":                    [2, 2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"spline_order\":                  3\n",
            "\"stack_types\":                   ['trend', 'seasonality']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64, 64]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 231 K  | train\n",
            "-------------------------------------------------------\n",
            "231 K     Trainable params\n",
            "0         Non-trainable params\n",
            "231 K     Total params\n",
            "0.925     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 20984/20984 [14:29<00:00, 24.14it/s, v_num=ed_1, train_loss_step=0.0314]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.85it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.63it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.25it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.38it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.38it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1: 100% 20984/20984 [14:49<00:00, 23.58it/s, v_num=ed_1, train_loss_step=0.0518, val_loss=0.0518, train_loss_epoch=0.0606]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.09it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.16it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 22.19it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 22.24it/s]\u001b[A\n",
            "Epoch 2: 100% 20984/20984 [14:58<00:00, 23.34it/s, v_num=ed_1, train_loss_step=0.0646, val_loss=0.0505, train_loss_epoch=0.0522]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.35it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.36it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.42it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.54it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.58it/s]\u001b[A\n",
            "Epoch 3: 100% 20984/20984 [14:55<00:00, 23.42it/s, v_num=ed_1, train_loss_step=0.0607, val_loss=0.0509, train_loss_epoch=0.0519]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 20.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.56it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.01it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 22.10it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 22.14it/s]\u001b[A\n",
            "Epoch 4: 100% 20984/20984 [14:53<00:00, 23.50it/s, v_num=ed_1, train_loss_step=0.0625, val_loss=0.0516, train_loss_epoch=0.0528]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.55it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.79it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.11it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 22.18it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 22.21it/s]\u001b[A\n",
            "Epoch 5: 100% 20984/20984 [14:55<00:00, 23.43it/s, v_num=ed_1, train_loss_step=0.0489, val_loss=0.052, train_loss_epoch=0.0537]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.37it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.61it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.60it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.73it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.80it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.81it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.80it/s]\u001b[A\n",
            "Epoch 6: 100% 20984/20984 [14:58<00:00, 23.37it/s, v_num=ed_1, train_loss_step=0.100, val_loss=0.0521, train_loss_epoch=0.0541] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.20it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.15it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.02it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.91it/s]\u001b[A\n",
            "Epoch 7:   8% 1580/20984 [01:10<14:26, 22.40it/s, v_num=ed_1, train_loss_step=0.0667, val_loss=0.052, train_loss_epoch=0.054]\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
            "Epoch 7:   8% 1580/20984 [01:11<14:37, 22.10it/s, v_num=ed_1, train_loss_step=0.0667, val_loss=0.052, train_loss_epoch=0.054]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### По 3 слоя из 16 нейронов"
      ],
      "metadata": {
        "id": "GZbPcFi-kiBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/KAN_BEATS/ECL_interp.py"
      ],
      "metadata": {
        "id": "g7OMxkW5ur7V",
        "outputId": "e6c55908-2d71-4fa4-dd50-c57b072c14e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "{'hist_len': 48, 'pred_len': 12, 'batch_size': 128, 'max_epochs': 10, 'lr': 0.0001, 'optimizer': 'AdamW', 'optimizer_betas': (0.95, 0.9), 'optimizer_weight_decay': 1e-05, 'lr_scheduler': 'StepLR', 'lr_step_size': 1, 'lr_gamma': 0.5, 'gradient_clip_val': 5, 'val_metric': 'val_loss', 'test_metric': 'test_mae', 'es_patience': 10, 'norm_variable': True, 'norm_time_feature': False, 'include_time_feature': False, 'time_feature_cls': ['tod', 'dow'], 'file_format': 'csv', 'num_workers': 2, 'dataset_name': 'ECL', 'var_num': 321, 'freq': 60, 'data_split': [21043, 2630, 2631], 'model_name': 'KAN_BEATS', 'var_cut': 10, 'batch_sampler': 'synchronized', 'grid_size': 3, 'spline_order': 3, 'stack_types': ['trend', 'seasonality'], 'num_blocks': [2, 2], 'num_block_layers': [3, 3], 'widths': [16, 16], 'sharing': False, 'expansion_coefficient_lengths': [3, 12], 'backcast_loss_ratio': 0.1, 'loss': MAE(), 'log_interval': 10, 'log_gradient_flow': False, 'weight_decay': 0.01, 'learning_rate': 0.0001, 'reduce_on_plateau_patience': 10, 'seed': 1, 'data_root': 'drive/MyDrive/VKR/Data/Time series', 'save_root': 'drive/MyDrive/VKR/Results/save', 'devices': 'auto', 'use_wandb': 0, 'exp_time': '270525_0119', 'exp_dir': 'drive/MyDrive/VKR/Results/save/KAN_BEATS_ECL/270525_0119/seed_1'}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "257774  21038  0.377660   9\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "\n",
            "[210430 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21043   21043  0.051095   0\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "...       ...       ...  ..\n",
            "260404  23668  0.196809   9\n",
            "260405  23669  0.199468   9\n",
            "260406  23670  0.199468   9\n",
            "260407  23671  0.091755   9\n",
            "260408  23672  0.117021   9\n",
            "\n",
            "[26300 rows x 3 columns]\n",
            "        index  variable  id\n",
            "23673   23673  0.467153   0\n",
            "23674   23674  0.452555   0\n",
            "23675   23675  0.437956   0\n",
            "23676   23676  0.664234   0\n",
            "23677   23677  0.452555   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[26310 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 20984 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "   | Name                                      | Type                  | Params | Mode \n",
            "---------------------------------------------------------------------------------------------\n",
            "0  | loss                                      | MAE                   | 0      | train\n",
            "1  | logging_metrics                           | ModuleList            | 0      | train\n",
            "2  | logging_metrics.0                         | SMAPE                 | 0      | train\n",
            "3  | logging_metrics.1                         | MAE                   | 0      | train\n",
            "4  | logging_metrics.2                         | RMSE                  | 0      | train\n",
            "5  | logging_metrics.3                         | MAPE                  | 0      | train\n",
            "6  | logging_metrics.4                         | MASE                  | 0      | train\n",
            "7  | logging_metrics.5                         | customR2Score         | 0      | train\n",
            "8  | net_blocks                                | ModuleList            | 33.2 K | train\n",
            "9  | net_blocks.0                              | KANBEATSTrendBlock    | 8.2 K  | train\n",
            "10 | net_blocks.0.kan                          | eff_KAN               | 8.2 K  | train\n",
            "11 | net_blocks.0.kan.layers                   | ModuleList            | 8.2 K  | train\n",
            "12 | net_blocks.0.kan.layers.0                 | KANLinear             | 6.1 K  | train\n",
            "13 | net_blocks.0.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "14 | net_blocks.0.kan.layers.1                 | KANLinear             | 2.0 K  | train\n",
            "15 | net_blocks.0.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "16 | net_blocks.0.theta_f_fc                   | Linear                | 48     | train\n",
            "17 | net_blocks.1                              | KANBEATSTrendBlock    | 8.2 K  | train\n",
            "18 | net_blocks.1.kan                          | eff_KAN               | 8.2 K  | train\n",
            "19 | net_blocks.1.kan.layers                   | ModuleList            | 8.2 K  | train\n",
            "20 | net_blocks.1.kan.layers.0                 | KANLinear             | 6.1 K  | train\n",
            "21 | net_blocks.1.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "22 | net_blocks.1.kan.layers.1                 | KANLinear             | 2.0 K  | train\n",
            "23 | net_blocks.1.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "24 | net_blocks.1.theta_f_fc                   | Linear                | 48     | train\n",
            "25 | net_blocks.2                              | KANBEATSSeasonalBlock | 8.4 K  | train\n",
            "26 | net_blocks.2.kan                          | eff_KAN               | 8.2 K  | train\n",
            "27 | net_blocks.2.kan.layers                   | ModuleList            | 8.2 K  | train\n",
            "28 | net_blocks.2.kan.layers.0                 | KANLinear             | 6.1 K  | train\n",
            "29 | net_blocks.2.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "30 | net_blocks.2.kan.layers.1                 | KANLinear             | 2.0 K  | train\n",
            "31 | net_blocks.2.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "32 | net_blocks.2.theta_f_fc                   | Linear                | 192    | train\n",
            "33 | net_blocks.3                              | KANBEATSSeasonalBlock | 8.4 K  | train\n",
            "34 | net_blocks.3.kan                          | eff_KAN               | 8.2 K  | train\n",
            "35 | net_blocks.3.kan.layers                   | ModuleList            | 8.2 K  | train\n",
            "36 | net_blocks.3.kan.layers.0                 | KANLinear             | 6.1 K  | train\n",
            "37 | net_blocks.3.kan.layers.0.base_activation | SiLU                  | 0      | train\n",
            "38 | net_blocks.3.kan.layers.1                 | KANLinear             | 2.0 K  | train\n",
            "39 | net_blocks.3.kan.layers.1.base_activation | SiLU                  | 0      | train\n",
            "40 | net_blocks.3.theta_f_fc                   | Linear                | 192    | train\n",
            "---------------------------------------------------------------------------------------------\n",
            "33.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "33.2 K    Total params\n",
            "0.133     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/content/EasyTSF/easytsf/model/KAN_BEATS.py:1228: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  90% 90/100 [00:04<00:00, 22.03it/s]\n",
            "LR finder stopped early after 90 steps due to diverging loss.\n",
            "Learning rate set to 5.623413251903491e-05\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_0c912404-53c3-4295-b2b1-0f03a5fb46af.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_0c912404-53c3-4295-b2b1-0f03a5fb46af.ckpt\n",
            "suggested learning rate: 5.623413251903491e-05\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                48\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 48, 'min_encoder_length': 48, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [3, 12]\n",
            "\"grid_size\":                     3\n",
            "\"learning_rate\":                 5.623413251903491e-05\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [3, 3]\n",
            "\"num_blocks\":                    [2, 2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"spline_order\":                  3\n",
            "\"stack_types\":                   ['trend', 'seasonality']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [16, 16]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 33.2 K | train\n",
            "-------------------------------------------------------\n",
            "33.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "33.2 K    Total params\n",
            "0.133     Total estimated model params size (MB)\n",
            "41        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 20984/20984 [14:19<00:00, 24.40it/s, v_num=ed_1, train_loss_step=0.0369]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 22.95it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.33it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.65it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.73it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.95it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:06<00:01, 23.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 23.13it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 23.22it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 23.22it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1: 100% 20984/20984 [14:41<00:00, 23.80it/s, v_num=ed_1, train_loss_step=0.0581, val_loss=0.0509, train_loss_epoch=0.0548]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.45it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 21.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.79it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.00it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.90it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.88it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:01, 20.69it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 20.83it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 20.88it/s]\u001b[A\n",
            "Epoch 2: 100% 20984/20984 [14:45<00:00, 23.69it/s, v_num=ed_1, train_loss_step=0.0616, val_loss=0.0507, train_loss_epoch=0.0516]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.48it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.45it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 22.57it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.58it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.63it/s]\u001b[A\n",
            "Epoch 3: 100% 20984/20984 [14:49<00:00, 23.60it/s, v_num=ed_1, train_loss_step=0.0511, val_loss=0.0506, train_loss_epoch=0.0515]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 24.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:06, 24.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 23.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.73it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 22.83it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.80it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.83it/s]\u001b[A\n",
            "Epoch 4: 100% 20984/20984 [14:45<00:00, 23.69it/s, v_num=ed_1, train_loss_step=0.0592, val_loss=0.0506, train_loss_epoch=0.0514]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 23.00it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 23.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 23.15it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 23.26it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 23.18it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:06<00:01, 23.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 22.98it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.93it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.97it/s]\u001b[A\n",
            "Epoch 5: 100% 20984/20984 [14:55<00:00, 23.43it/s, v_num=ed_1, train_loss_step=0.0475, val_loss=0.0506, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 22.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.86it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.65it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.62it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.60it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.36it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.42it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.45it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.49it/s]\u001b[A\n",
            "Epoch 6: 100% 20984/20984 [14:50<00:00, 23.57it/s, v_num=ed_1, train_loss_step=0.0855, val_loss=0.0505, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 22.94it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.57it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.31it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.46it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.46it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.49it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.53it/s]\u001b[A\n",
            "Epoch 7: 100% 20984/20984 [14:57<00:00, 23.38it/s, v_num=ed_1, train_loss_step=0.036, val_loss=0.0506, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 20.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 21.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 21.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 21.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 21.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 21.89it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 21.97it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 21.94it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:09<00:00, 21.94it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:09<00:00, 21.98it/s]\u001b[A\n",
            "Epoch 8: 100% 20984/20984 [14:51<00:00, 23.53it/s, v_num=ed_1, train_loss_step=0.0558, val_loss=0.0506, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:07, 23.35it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:06, 23.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 23.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 23.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.77it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:07<00:00, 22.65it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.62it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.67it/s]\u001b[A\n",
            "Epoch 9: 100% 20984/20984 [14:51<00:00, 23.53it/s, v_num=ed_1, train_loss_step=0.0567, val_loss=0.0506, train_loss_epoch=0.0513]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/201 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/201 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/201 [00:00<00:08, 21.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/201 [00:01<00:07, 22.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/201 [00:02<00:06, 22.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 80/201 [00:03<00:05, 22.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 100/201 [00:04<00:04, 22.61it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 120/201 [00:05<00:03, 22.27it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 140/201 [00:06<00:02, 22.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 160/201 [00:07<00:01, 22.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 180/201 [00:08<00:00, 22.35it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 200/201 [00:08<00:00, 22.44it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 201/201 [00:08<00:00, 22.48it/s]\u001b[A\n",
            "Epoch 9: 100% 20984/20984 [15:01<00:00, 23.28it/s, v_num=ed_1, train_loss_step=0.0567, val_loss=0.0505, train_loss_epoch=0.0513]`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "Epoch 9: 100% 20984/20984 [15:11<00:00, 23.02it/s, v_num=ed_1, train_loss_step=0.0567, val_loss=0.0505, train_loss_epoch=0.0513]\n",
            "Training time: 9069.723 s (151.162 min, 2.519 h)\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/KAN_BEATS_ECL/270525_0119/seed_1/checkpoints/epoch=5-step=125904.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at drive/MyDrive/VKR/Results/save/KAN_BEATS_ECL/270525_0119/seed_1/checkpoints/epoch=5-step=125904.ckpt\n",
            "Testing DataLoader 0: 100% 201/201 [00:07<00:00, 25.78it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045118432492017746   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     4297.1982421875     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MASE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3374748229980469    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_RMSE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06181374937295914   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16434329748153687   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m   test_customR2Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00023527351731900126  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045118432492017746   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_backcast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0015912732342258096  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_forecast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045118432492017746   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6wmJKhhLusBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-BEATS"
      ],
      "metadata": {
        "id": "Dvx6KZLZ9hJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/N_BEATS/ECL.py"
      ],
      "metadata": {
        "id": "Q69MJ_qV9i9j",
        "outputId": "7b5f3f9f-9954-47d0-81f1-dfbd8b0f6f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "255143  18407  0.365691   9\n",
            "255144  18408  0.324468   9\n",
            "255145  18409  0.293883   9\n",
            "255146  18410  0.285904   9\n",
            "255147  18411  0.265957   9\n",
            "\n",
            "[184120 rows x 3 columns]\n",
            "        index  variable  id\n",
            "18412   18412  0.087591   0\n",
            "18413   18413  0.087591   0\n",
            "18414   18414  0.080292   0\n",
            "18415   18415  0.080292   0\n",
            "18416   18416  0.102190   0\n",
            "...       ...       ...  ..\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "257779  21043  0.191489   9\n",
            "\n",
            "[26320 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "21048   21048  0.094891   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[52600 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 18377 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                24\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 24, 'min_encoder_length': 24, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [32]\n",
            "\"learning_rate\":                 0.001\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [2]\n",
            "\"num_blocks\":                    [2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"stack_types\":                   ['generic']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64]\n",
            "   | Name                     | Type               | Params | Mode \n",
            "-------------------------------------------------------------------------\n",
            "0  | loss                     | MAE                | 0      | train\n",
            "1  | logging_metrics          | ModuleList         | 0      | train\n",
            "2  | logging_metrics.0        | SMAPE              | 0      | train\n",
            "3  | logging_metrics.1        | MAE                | 0      | train\n",
            "4  | logging_metrics.2        | RMSE               | 0      | train\n",
            "5  | logging_metrics.3        | MAPE               | 0      | train\n",
            "6  | logging_metrics.4        | MASE               | 0      | train\n",
            "7  | net_blocks               | ModuleList         | 22.1 K | train\n",
            "8  | net_blocks.0             | NBEATSGenericBlock | 11.0 K | train\n",
            "9  | net_blocks.0.fc          | Sequential         | 5.8 K  | train\n",
            "10 | net_blocks.0.fc.0        | Linear             | 1.6 K  | train\n",
            "11 | net_blocks.0.fc.1        | ReLU               | 0      | train\n",
            "12 | net_blocks.0.fc.2        | Sequential         | 4.2 K  | train\n",
            "13 | net_blocks.0.fc.2.0      | Dropout            | 0      | train\n",
            "14 | net_blocks.0.fc.2.1      | Linear             | 4.2 K  | train\n",
            "15 | net_blocks.0.fc.3        | ReLU               | 0      | train\n",
            "16 | net_blocks.0.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "17 | net_blocks.0.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "18 | net_blocks.0.backcast_fc | Linear             | 792    | train\n",
            "19 | net_blocks.0.forecast_fc | Linear             | 396    | train\n",
            "20 | net_blocks.1             | NBEATSGenericBlock | 11.0 K | train\n",
            "21 | net_blocks.1.fc          | Sequential         | 5.8 K  | train\n",
            "22 | net_blocks.1.fc.0        | Linear             | 1.6 K  | train\n",
            "23 | net_blocks.1.fc.1        | ReLU               | 0      | train\n",
            "24 | net_blocks.1.fc.2        | Sequential         | 4.2 K  | train\n",
            "25 | net_blocks.1.fc.2.0      | Dropout            | 0      | train\n",
            "26 | net_blocks.1.fc.2.1      | Linear             | 4.2 K  | train\n",
            "27 | net_blocks.1.fc.3        | ReLU               | 0      | train\n",
            "28 | net_blocks.1.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "29 | net_blocks.1.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "30 | net_blocks.1.backcast_fc | Linear             | 792    | train\n",
            "31 | net_blocks.1.forecast_fc | Linear             | 396    | train\n",
            "-------------------------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "32        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 22.1 K | train\n",
            "-------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "32        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 18377/18377 [05:41<00:00, 53.84it/s, v_num=ed_1, train_loss_step=0.0685]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/203 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/203 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/203 [00:00<00:07, 22.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/203 [00:01<00:07, 23.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/203 [00:02<00:06, 23.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  39% 80/203 [00:03<00:05, 23.43it/s]\u001b[A\n",
            "Validation DataLoader 0:  49% 100/203 [00:04<00:04, 23.43it/s]\u001b[A\n",
            "Validation DataLoader 0:  59% 120/203 [00:05<00:03, 23.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  69% 140/203 [00:06<00:02, 23.22it/s]\u001b[A\n",
            "Validation DataLoader 0:  79% 160/203 [00:06<00:01, 23.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 180/203 [00:07<00:00, 23.03it/s]\u001b[A\n",
            "Validation DataLoader 0:  99% 200/203 [00:08<00:00, 22.86it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 203/203 [00:08<00:00, 22.84it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 0: 100% 18377/18377 [05:50<00:00, 52.44it/s, v_num=ed_1, train_loss_step=0.0685, val_loss=0.0625, train_loss_epoch=0.0716]`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "Epoch 0: 100% 18377/18377 [05:52<00:00, 52.18it/s, v_num=ed_1, train_loss_step=0.0685, val_loss=0.0625, train_loss_epoch=0.0716]\n",
            "Training time: 356.432 s (5.941 min, 0.099 h)\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/N_BEATS_ECL/260525_1902/seed_1/checkpoints/epoch=0-step=18377.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at drive/MyDrive/VKR/Results/save/N_BEATS_ECL/260525_1902/seed_1/checkpoints/epoch=0-step=18377.ckpt\n",
            "Testing DataLoader 0: 100% 409/409 [00:16<00:00, 25.37it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06336717307567596   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      5546.01171875      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MASE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8850963115692139    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_RMSE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08142081648111343   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22307169437408447   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06336717307567596   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_backcast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.002776762703433633   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_forecast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06336717307567596   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С подбором lr"
      ],
      "metadata": {
        "id": "-8_FyXByXbfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/N_BEATS/ECL.py"
      ],
      "metadata": {
        "id": "SkQKOGhWXXOL",
        "outputId": "5ada4437-2f57-4557-977d-6555d99faee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "255143  18407  0.365691   9\n",
            "255144  18408  0.324468   9\n",
            "255145  18409  0.293883   9\n",
            "255146  18410  0.285904   9\n",
            "255147  18411  0.265957   9\n",
            "\n",
            "[184120 rows x 3 columns]\n",
            "        index  variable  id\n",
            "18412   18412  0.087591   0\n",
            "18413   18413  0.087591   0\n",
            "18414   18414  0.080292   0\n",
            "18415   18415  0.080292   0\n",
            "18416   18416  0.102190   0\n",
            "...       ...       ...  ..\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "257779  21043  0.191489   9\n",
            "\n",
            "[26320 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "21048   21048  0.094891   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[52600 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 18377 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                24\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 24, 'min_encoder_length': 24, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [32]\n",
            "\"learning_rate\":                 0.001\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [2]\n",
            "\"num_blocks\":                    [2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"stack_types\":                   ['generic']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64]\n",
            "   | Name                     | Type               | Params | Mode \n",
            "-------------------------------------------------------------------------\n",
            "0  | loss                     | MAE                | 0      | train\n",
            "1  | logging_metrics          | ModuleList         | 0      | train\n",
            "2  | logging_metrics.0        | SMAPE              | 0      | train\n",
            "3  | logging_metrics.1        | MAE                | 0      | train\n",
            "4  | logging_metrics.2        | RMSE               | 0      | train\n",
            "5  | logging_metrics.3        | MAPE               | 0      | train\n",
            "6  | logging_metrics.4        | MASE               | 0      | train\n",
            "7  | logging_metrics.5        | customR2Score      | 0      | train\n",
            "8  | net_blocks               | ModuleList         | 22.1 K | train\n",
            "9  | net_blocks.0             | NBEATSGenericBlock | 11.0 K | train\n",
            "10 | net_blocks.0.fc          | Sequential         | 5.8 K  | train\n",
            "11 | net_blocks.0.fc.0        | Linear             | 1.6 K  | train\n",
            "12 | net_blocks.0.fc.1        | ReLU               | 0      | train\n",
            "13 | net_blocks.0.fc.2        | Sequential         | 4.2 K  | train\n",
            "14 | net_blocks.0.fc.2.0      | Dropout            | 0      | train\n",
            "15 | net_blocks.0.fc.2.1      | Linear             | 4.2 K  | train\n",
            "16 | net_blocks.0.fc.3        | ReLU               | 0      | train\n",
            "17 | net_blocks.0.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "18 | net_blocks.0.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "19 | net_blocks.0.backcast_fc | Linear             | 792    | train\n",
            "20 | net_blocks.0.forecast_fc | Linear             | 396    | train\n",
            "21 | net_blocks.1             | NBEATSGenericBlock | 11.0 K | train\n",
            "22 | net_blocks.1.fc          | Sequential         | 5.8 K  | train\n",
            "23 | net_blocks.1.fc.0        | Linear             | 1.6 K  | train\n",
            "24 | net_blocks.1.fc.1        | ReLU               | 0      | train\n",
            "25 | net_blocks.1.fc.2        | Sequential         | 4.2 K  | train\n",
            "26 | net_blocks.1.fc.2.0      | Dropout            | 0      | train\n",
            "27 | net_blocks.1.fc.2.1      | Linear             | 4.2 K  | train\n",
            "28 | net_blocks.1.fc.3        | ReLU               | 0      | train\n",
            "29 | net_blocks.1.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "30 | net_blocks.1.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "31 | net_blocks.1.backcast_fc | Linear             | 792    | train\n",
            "32 | net_blocks.1.forecast_fc | Linear             | 396    | train\n",
            "-------------------------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "33        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/models/nbeats/_nbeats.py:375: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  99% 99/100 [00:02<00:00, 53.50it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
            "Finding best initial lr: 100% 100/100 [00:02<00:00, 48.47it/s]\n",
            "Learning rate set to 5.623413251903491e-05\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_fe424fdb-3192-4eef-b146-81c774b5f958.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_fe424fdb-3192-4eef-b146-81c774b5f958.ckpt\n",
            "suggested learning rate: 5.623413251903491e-05\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type       | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | loss            | MAE        | 0      | train\n",
            "1 | logging_metrics | ModuleList | 0      | train\n",
            "2 | net_blocks      | ModuleList | 22.1 K | train\n",
            "-------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "33        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 18377/18377 [05:46<00:00, 53.02it/s, v_num=ed_1, train_loss_step=0.0689]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/203 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/203 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 20/203 [00:00<00:07, 24.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 40/203 [00:01<00:06, 23.90it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 60/203 [00:02<00:06, 23.51it/s]\u001b[A\n",
            "Validation DataLoader 0:  39% 80/203 [00:03<00:05, 23.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  49% 100/203 [00:04<00:04, 23.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  59% 120/203 [00:05<00:03, 23.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  69% 140/203 [00:06<00:02, 23.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  79% 160/203 [00:06<00:01, 23.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  89% 180/203 [00:07<00:00, 23.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  99% 200/203 [00:08<00:00, 23.10it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 203/203 [00:08<00:00, 23.07it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/ray/train/_internal/session.py:657: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 0: 100% 18377/18377 [05:55<00:00, 51.67it/s, v_num=ed_1, train_loss_step=0.0689, val_loss=0.0624, train_loss_epoch=0.0719]`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "Epoch 0: 100% 18377/18377 [05:57<00:00, 51.41it/s, v_num=ed_1, train_loss_step=0.0689, val_loss=0.0624, train_loss_epoch=0.0719]\n",
            "Training time: 360.026 s (6.000 min, 0.100 h)\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/N_BEATS_ECL/260525_1912/seed_1/checkpoints/epoch=0-step=18377.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at drive/MyDrive/VKR/Results/save/N_BEATS_ECL/260525_1912/seed_1/checkpoints/epoch=0-step=18377.ckpt\n",
            "Testing DataLoader 0: 100% 409/409 [00:16<00:00, 25.39it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06329068541526794   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5491.01806640625     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_MASE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8848509788513184    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_RMSE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08147545158863068   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2230139970779419    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m   test_customR2Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m -2.9475204428308643e-05 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06329068541526794   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_backcast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0027765827253460884  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    val_forecast_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06329068541526794   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "График к предыдущему"
      ],
      "metadata": {
        "id": "lbsQtcMUY2Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python EasyTSF/kan_beats_exp.py -c EasyTSF/config/reproduce_conf/N_BEATS/ECL.py"
      ],
      "metadata": {
        "id": "OZa-DOqpYzC-",
        "outputId": "2f6388e9-3cad-4ff3-efb3-65cc505c3a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 1\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "        index  variable  id\n",
            "0           0  0.102190   0\n",
            "1           1  0.131387   0\n",
            "2           2  0.153285   0\n",
            "3           3  0.145985   0\n",
            "4           4  0.160584   0\n",
            "...       ...       ...  ..\n",
            "255143  18407  0.365691   9\n",
            "255144  18408  0.324468   9\n",
            "255145  18409  0.293883   9\n",
            "255146  18410  0.285904   9\n",
            "255147  18411  0.265957   9\n",
            "\n",
            "[184120 rows x 3 columns]\n",
            "        index  variable  id\n",
            "18412   18412  0.087591   0\n",
            "18413   18413  0.087591   0\n",
            "18414   18414  0.080292   0\n",
            "18415   18415  0.080292   0\n",
            "18416   18416  0.102190   0\n",
            "...       ...       ...  ..\n",
            "257775  21039  0.484043   9\n",
            "257776  21040  0.526596   9\n",
            "257777  21041  0.497340   9\n",
            "257778  21042  0.515957   9\n",
            "257779  21043  0.191489   9\n",
            "\n",
            "[26320 rows x 3 columns]\n",
            "        index  variable  id\n",
            "21044   21044  0.065693   0\n",
            "21045   21045  0.072993   0\n",
            "21046   21046  0.160584   0\n",
            "21047   21047  0.145985   0\n",
            "21048   21048  0.094891   0\n",
            "...       ...       ...  ..\n",
            "263035  26299  0.466755   9\n",
            "263036  26300  0.434840   9\n",
            "263037  26301  0.376330   9\n",
            "263038  26302  0.388298   9\n",
            "263039  26303  0.390957   9\n",
            "\n",
            "[52600 rows x 3 columns]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/samplers.py:96: UserWarning: Less than 128 samples available for 18377 prediction times. Use batch size smaller than 128. First 10 prediction times with small batch sizes: [25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "\"backcast_loss_ratio\":           0.1\n",
            "\"context_length\":                24\n",
            "\"dataset_parameters\":            {'time_idx': 'index', 'target': 'variable', 'group_ids': ['id'], 'weight': None, 'max_encoder_length': 24, 'min_encoder_length': 24, 'min_prediction_idx': 0, 'min_prediction_length': 12, 'max_prediction_length': 12, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['variable'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            "), 'categorical_encoders': {'id': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {}, 'randomize_length': None, 'predict_mode': False}\n",
            "\"dropout\":                       0.1\n",
            "\"expansion_coefficient_lengths\": [32]\n",
            "\"learning_rate\":                 0.001\n",
            "\"log_gradient_flow\":             False\n",
            "\"log_interval\":                  10\n",
            "\"log_val_interval\":              10\n",
            "\"monotone_constraints\":          {}\n",
            "\"num_block_layers\":              [2]\n",
            "\"num_blocks\":                    [2]\n",
            "\"optimizer\":                     adam\n",
            "\"optimizer_params\":              None\n",
            "\"output_transformer\":            EncoderNormalizer(\n",
            "\tmethod='standard',\n",
            "\tcenter=True,\n",
            "\tmax_length=None,\n",
            "\ttransformation=None,\n",
            "\tmethod_kwargs={}\n",
            ")\n",
            "\"prediction_length\":             12\n",
            "\"reduce_on_plateau_min_lr\":      1e-05\n",
            "\"reduce_on_plateau_patience\":    10\n",
            "\"reduce_on_plateau_reduction\":   2.0\n",
            "\"sharing\":                       False\n",
            "\"stack_types\":                   ['generic']\n",
            "\"weight_decay\":                  0.01\n",
            "\"widths\":                        [64]\n",
            "   | Name                     | Type               | Params | Mode \n",
            "-------------------------------------------------------------------------\n",
            "0  | loss                     | MAE                | 0      | train\n",
            "1  | logging_metrics          | ModuleList         | 0      | train\n",
            "2  | logging_metrics.0        | SMAPE              | 0      | train\n",
            "3  | logging_metrics.1        | MAE                | 0      | train\n",
            "4  | logging_metrics.2        | RMSE               | 0      | train\n",
            "5  | logging_metrics.3        | MAPE               | 0      | train\n",
            "6  | logging_metrics.4        | MASE               | 0      | train\n",
            "7  | logging_metrics.5        | customR2Score      | 0      | train\n",
            "8  | net_blocks               | ModuleList         | 22.1 K | train\n",
            "9  | net_blocks.0             | NBEATSGenericBlock | 11.0 K | train\n",
            "10 | net_blocks.0.fc          | Sequential         | 5.8 K  | train\n",
            "11 | net_blocks.0.fc.0        | Linear             | 1.6 K  | train\n",
            "12 | net_blocks.0.fc.1        | ReLU               | 0      | train\n",
            "13 | net_blocks.0.fc.2        | Sequential         | 4.2 K  | train\n",
            "14 | net_blocks.0.fc.2.0      | Dropout            | 0      | train\n",
            "15 | net_blocks.0.fc.2.1      | Linear             | 4.2 K  | train\n",
            "16 | net_blocks.0.fc.3        | ReLU               | 0      | train\n",
            "17 | net_blocks.0.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "18 | net_blocks.0.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "19 | net_blocks.0.backcast_fc | Linear             | 792    | train\n",
            "20 | net_blocks.0.forecast_fc | Linear             | 396    | train\n",
            "21 | net_blocks.1             | NBEATSGenericBlock | 11.0 K | train\n",
            "22 | net_blocks.1.fc          | Sequential         | 5.8 K  | train\n",
            "23 | net_blocks.1.fc.0        | Linear             | 1.6 K  | train\n",
            "24 | net_blocks.1.fc.1        | ReLU               | 0      | train\n",
            "25 | net_blocks.1.fc.2        | Sequential         | 4.2 K  | train\n",
            "26 | net_blocks.1.fc.2.0      | Dropout            | 0      | train\n",
            "27 | net_blocks.1.fc.2.1      | Linear             | 4.2 K  | train\n",
            "28 | net_blocks.1.fc.3        | ReLU               | 0      | train\n",
            "29 | net_blocks.1.theta_b_fc  | Linear             | 2.0 K  | train\n",
            "30 | net_blocks.1.theta_f_fc  | Linear             | 2.0 K  | train\n",
            "31 | net_blocks.1.backcast_fc | Linear             | 792    | train\n",
            "32 | net_blocks.1.forecast_fc | Linear             | 396    | train\n",
            "-------------------------------------------------------------------------\n",
            "22.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "22.1 K    Total params\n",
            "0.088     Total estimated model params size (MB)\n",
            "33        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/models/nbeats/_nbeats.py:375: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
            "Finding best initial lr:  99% 99/100 [00:02<00:00, 45.50it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
            "Finding best initial lr: 100% 100/100 [00:02<00:00, 43.88it/s]\n",
            "Learning rate set to 5.623413251903491e-05\n",
            "Restoring states from the checkpoint path at drive/MyDrive/VKR/Results/save/.lr_find_6644715f-fa30-49b7-a0a4-d8abad041c64.ckpt\n",
            "Restored all states from the checkpoint at drive/MyDrive/VKR/Results/save/.lr_find_6644715f-fa30-49b7-a0a4-d8abad041c64.ckpt\n",
            "suggested learning rate: 5.623413251903491e-05\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(600x800)\n",
            "Figure(640x480)\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ]
}